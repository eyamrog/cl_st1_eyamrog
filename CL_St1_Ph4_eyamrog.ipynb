{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 4 - eyamrog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc807bb-6cbf-4b7c-ae5b-b70cf7fce407",
   "metadata": {},
   "source": [
    "The aim of this phase is to PDF scrape the selected texts from the archive of preprints of [SciELO](https://scielo.org/) (Scientific Electronic Library Online), isolate the paragraphs of the articles and review them with ChatGPT.\n",
    "\n",
    "- [SciELO Preprints](https://preprints.scielo.org/index.php/scielo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685d8b0-7715-45a6-9489-2d3db9b346c8",
   "metadata": {},
   "source": [
    "## Required Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e16e73-b1b9-4838-8cce-a29dc300868e",
   "metadata": {},
   "source": [
    "- beautifulsoup4\n",
    "- PyMuPDF\n",
    "- lxml\n",
    "- pandas\n",
    "- requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa922755-c4d6-4008-9aad-d35e33b18ed7",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ebcaf3-5b41-474c-9394-ebc8bec9005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import fitz # PyMuPDF\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd82a71-ff9c-4e3c-9f7f-f7168a0b7918",
   "metadata": {},
   "source": [
    "## Defining input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7520b-1da6-450c-8c74-e424c1ead951",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'cl_st1_ph3_eyamrog'\n",
    "output_directory = 'cl_st1_ph4_eyamrog'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621c7d9-1a7b-4ea4-89ff-c3479b468fdc",
   "metadata": {},
   "source": [
    "## Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb8dd16-0676-4e83-8867-0e676890b0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory successfully created.\n"
     ]
    }
   ],
   "source": [
    "# Check if the output directory already exists. If it does, do nothing. If it doesn't exist, create it.\n",
    "if os.path.exists(output_directory):\n",
    "    print('Output directory already exists.')\n",
    "else:\n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "        print('Output directory successfully created.')\n",
    "    except OSError as e:\n",
    "        print('Failed to create the directory:', e)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc346c15-46b9-4e1d-9fbc-d2c03f146504",
   "metadata": {},
   "source": [
    "## PDF Scraping `SciELO Preprints` archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7f80a-fee0-487f-b313-9543a0ddb014",
   "metadata": {},
   "source": [
    "### Importing the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5e583f-797c-4264-9504-fd82194ce67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en = pd.read_json(f'{input_directory}/scielo_erpp_pp.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9ebf24-16df-494f-8641-fb110867b667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title           object\n",
       "URL             object\n",
       "Authors         object\n",
       "Published       object\n",
       "PDF Language    object\n",
       "PDF URL         object\n",
       "Submitted        int64\n",
       "Posted           int64\n",
       "Text            object\n",
       "Text ID         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scielo_preprint_preChatGPT_en.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa92a5ed-5739-4d02-b775-4feb7753d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en['Submitted'] = pd.to_datetime(df_scielo_preprint_preChatGPT_en['Submitted'], unit='ms')\n",
    "df_scielo_preprint_preChatGPT_en['Posted'] = pd.to_datetime(df_scielo_preprint_preChatGPT_en['Posted'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd0ed8e-7c82-4d6d-8e8e-ae71dccbbac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published</th>\n",
       "      <th>PDF Language</th>\n",
       "      <th>PDF URL</th>\n",
       "      <th>Submitted</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Fern flora of Viçosa, Minas Gerais State, Bra...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Nelson Túlio Lage Pena, Pedro Bond Schwartsburd</td>\n",
       "      <td>Submitted 11/22/2022 - Posted 11/23/2022</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>Publication status: Preprint has been publishe...</td>\n",
       "      <td>t000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assembling the perfect bacterial genome using ...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Ryan R. Wick, Louise M. Judd, Kathryn E. Holt</td>\n",
       "      <td>Submitted 11/11/2022 - Posted 11/11/2022</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>Publication status: Preprint has been publishe...</td>\n",
       "      <td>t000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON METHODOLOGY AND METHODS FOR ANALYSING CLASS...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Leonardo Goncalves Lago</td>\n",
       "      <td>Submitted 11/10/2022 - Posted 11/16/2022</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>Publication status: Preprint has been publishe...</td>\n",
       "      <td>t000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOBILIZING LINGUISTIC AND SEMIOTIC RESOURCES, ...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Estêvão Cabral, Marylin Martin-Jones</td>\n",
       "      <td>Submitted 11/07/2022 - Posted 11/07/2022</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>Publication status: Preprint has been submitte...</td>\n",
       "      <td>t000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PORTUGUESE AO PÉ DO BERIMBAU: ON CAPOEIRA AS A...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Mike Baynham, Jolana Hanusova</td>\n",
       "      <td>Submitted 11/04/2022 - Posted 11/04/2022</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>Publication status: Preprint has been submitte...</td>\n",
       "      <td>t000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Challenges in the fight against the COVID-19 p...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Eduardo Alexandrino Servolo Medeiros</td>\n",
       "      <td>Submitted 04/15/2020 - Posted 04/15/2020</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>*Corresponding author. E-mail: edubalaccih@gma...</td>\n",
       "      <td>t000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Information about the new coronavirus disease ...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Claudio Márcio Amaral de Oliveira  Lima</td>\n",
       "      <td>Submitted 04/13/2020 - Posted 04/13/2020</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>V\\nRadiol Bras. 2020 Mar/Abr;53(2):V–VI\\n0100-...</td>\n",
       "      <td>t000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>ACE2 diversity in placental mammals reveals th...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Bibiana Sampaio de Oliveira Fam, Pedro Vargas-...</td>\n",
       "      <td>Submitted 04/11/2020 - Posted 04/28/2020</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>Status: Preprint has been published in a journ...</td>\n",
       "      <td>t000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Coronavirus 2: Analysis of Regularity of Compl...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Yuri Morales-López</td>\n",
       "      <td>Submitted 04/10/2020 - Posted 06/04/2020</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>Publication status: Preprint has been publishe...</td>\n",
       "      <td>t000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>COVID-19 in Brazil: advantages of a socialized...</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>Julio Croda, Wanderson Kleber de  Oliveira, Ro...</td>\n",
       "      <td>Submitted 04/06/2020 - Posted 04/08/2020</td>\n",
       "      <td>PDF</td>\n",
       "      <td>https://preprints.scielo.org/index.php/scielo/...</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>1/6\\nRevista da Sociedade Brasileira de Medi...</td>\n",
       "      <td>t000315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    (Fern flora of Viçosa, Minas Gerais State, Bra...   \n",
       "1    Assembling the perfect bacterial genome using ...   \n",
       "2    ON METHODOLOGY AND METHODS FOR ANALYSING CLASS...   \n",
       "3    MOBILIZING LINGUISTIC AND SEMIOTIC RESOURCES, ...   \n",
       "4    PORTUGUESE AO PÉ DO BERIMBAU: ON CAPOEIRA AS A...   \n",
       "..                                                 ...   \n",
       "311  Challenges in the fight against the COVID-19 p...   \n",
       "312  Information about the new coronavirus disease ...   \n",
       "313  ACE2 diversity in placental mammals reveals th...   \n",
       "314  Coronavirus 2: Analysis of Regularity of Compl...   \n",
       "315  COVID-19 in Brazil: advantages of a socialized...   \n",
       "\n",
       "                                                   URL  \\\n",
       "0    https://preprints.scielo.org/index.php/scielo/...   \n",
       "1    https://preprints.scielo.org/index.php/scielo/...   \n",
       "2    https://preprints.scielo.org/index.php/scielo/...   \n",
       "3    https://preprints.scielo.org/index.php/scielo/...   \n",
       "4    https://preprints.scielo.org/index.php/scielo/...   \n",
       "..                                                 ...   \n",
       "311  https://preprints.scielo.org/index.php/scielo/...   \n",
       "312  https://preprints.scielo.org/index.php/scielo/...   \n",
       "313  https://preprints.scielo.org/index.php/scielo/...   \n",
       "314  https://preprints.scielo.org/index.php/scielo/...   \n",
       "315  https://preprints.scielo.org/index.php/scielo/...   \n",
       "\n",
       "                                               Authors  \\\n",
       "0      Nelson Túlio Lage Pena, Pedro Bond Schwartsburd   \n",
       "1        Ryan R. Wick, Louise M. Judd, Kathryn E. Holt   \n",
       "2                              Leonardo Goncalves Lago   \n",
       "3                 Estêvão Cabral, Marylin Martin-Jones   \n",
       "4                        Mike Baynham, Jolana Hanusova   \n",
       "..                                                 ...   \n",
       "311               Eduardo Alexandrino Servolo Medeiros   \n",
       "312            Claudio Márcio Amaral de Oliveira  Lima   \n",
       "313  Bibiana Sampaio de Oliveira Fam, Pedro Vargas-...   \n",
       "314                                 Yuri Morales-López   \n",
       "315  Julio Croda, Wanderson Kleber de  Oliveira, Ro...   \n",
       "\n",
       "                                    Published PDF Language  \\\n",
       "0    Submitted 11/22/2022 - Posted 11/23/2022          PDF   \n",
       "1    Submitted 11/11/2022 - Posted 11/11/2022          PDF   \n",
       "2    Submitted 11/10/2022 - Posted 11/16/2022          PDF   \n",
       "3    Submitted 11/07/2022 - Posted 11/07/2022          PDF   \n",
       "4    Submitted 11/04/2022 - Posted 11/04/2022          PDF   \n",
       "..                                        ...          ...   \n",
       "311  Submitted 04/15/2020 - Posted 04/15/2020          PDF   \n",
       "312  Submitted 04/13/2020 - Posted 04/13/2020          PDF   \n",
       "313  Submitted 04/11/2020 - Posted 04/28/2020          PDF   \n",
       "314  Submitted 04/10/2020 - Posted 06/04/2020          PDF   \n",
       "315  Submitted 04/06/2020 - Posted 04/08/2020          PDF   \n",
       "\n",
       "                                               PDF URL  Submitted     Posted  \\\n",
       "0    https://preprints.scielo.org/index.php/scielo/... 2022-11-22 2022-11-23   \n",
       "1    https://preprints.scielo.org/index.php/scielo/... 2022-11-11 2022-11-11   \n",
       "2    https://preprints.scielo.org/index.php/scielo/... 2022-11-10 2022-11-16   \n",
       "3    https://preprints.scielo.org/index.php/scielo/... 2022-11-07 2022-11-07   \n",
       "4    https://preprints.scielo.org/index.php/scielo/... 2022-11-04 2022-11-04   \n",
       "..                                                 ...        ...        ...   \n",
       "311  https://preprints.scielo.org/index.php/scielo/... 2020-04-15 2020-04-15   \n",
       "312  https://preprints.scielo.org/index.php/scielo/... 2020-04-13 2020-04-13   \n",
       "313  https://preprints.scielo.org/index.php/scielo/... 2020-04-11 2020-04-28   \n",
       "314  https://preprints.scielo.org/index.php/scielo/... 2020-04-10 2020-06-04   \n",
       "315  https://preprints.scielo.org/index.php/scielo/... 2020-04-06 2020-04-08   \n",
       "\n",
       "                                                  Text  Text ID  \n",
       "0    Publication status: Preprint has been publishe...  t000000  \n",
       "1    Publication status: Preprint has been publishe...  t000001  \n",
       "2    Publication status: Preprint has been publishe...  t000002  \n",
       "3    Publication status: Preprint has been submitte...  t000003  \n",
       "4    Publication status: Preprint has been submitte...  t000004  \n",
       "..                                                 ...      ...  \n",
       "311  *Corresponding author. E-mail: edubalaccih@gma...  t000311  \n",
       "312  V\\nRadiol Bras. 2020 Mar/Abr;53(2):V–VI\\n0100-...  t000312  \n",
       "313  Status: Preprint has been published in a journ...  t000313  \n",
       "314  Publication status: Preprint has been publishe...  t000314  \n",
       "315    1/6\\nRevista da Sociedade Brasileira de Medi...  t000315  \n",
       "\n",
       "[316 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scielo_preprint_preChatGPT_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc541f-c31b-4aa4-85ab-735b446ad5f9",
   "metadata": {},
   "source": [
    "### Extracting the articles in original PDF format and scraping them into TXT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c35b0-e30d-4b1a-8312-191d8d55e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to write to a file\n",
    "logging.basicConfig(\n",
    "    filename = f\"{output_directory}/scraping_log.txt\",\n",
    "    level = logging.INFO,\n",
    "    format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def scrape_pdf(pdf_byte_stream, output_txt):\n",
    "    try:\n",
    "        # Opening the PDF file\n",
    "        doc = fitz.open(stream=pdf_byte_stream, filetype='pdf')\n",
    "        \n",
    "        # Initialising an empty string to store the text\n",
    "        text = ''\n",
    "        \n",
    "        # Iterating through all the pages and extracting the text\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        \n",
    "        # Writing the extracted text to a text file in UTF-8 encoding\n",
    "        with open(output_txt, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(text)\n",
    "        \n",
    "        logging.info(f\"Text successfully extracted and saved to {output_txt}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text from PDF: {e}\")\n",
    "\n",
    "def save_pdf(pdf_byte_stream, output_pdf):\n",
    "    try:\n",
    "        with open(output_pdf, 'wb') as pdf_file:\n",
    "            pdf_file.write(pdf_byte_stream)\n",
    "        \n",
    "        logging.info(f\"PDF successfully saved to {output_pdf}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving PDF: {e}\")\n",
    "\n",
    "for index, row in df_scielo_preprint_preChatGPT_en.iterrows():\n",
    "    try:\n",
    "        article_page = requests.get(row['PDF URL'], verify=False)\n",
    "        soup = BeautifulSoup(article_page.content, 'lxml')\n",
    "        # Finding the <a> tag with the class 'download'\n",
    "        download_link = soup.find('a', class_='download')\n",
    "        article_pdf_link = download_link.get('href') if download_link else 'No PDF link'\n",
    "        \n",
    "        if article_pdf_link != 'No PDF link':\n",
    "            article = requests.get(article_pdf_link, verify=False)\n",
    "            # Scraping the article from the byte stream and saving it in the output directory\n",
    "            scrape_pdf(article.content, f\"{output_directory}/{row['Text ID']}.txt\")\n",
    "            # Saving the article in the output directory\n",
    "            save_pdf(article.content, f\"{output_directory}/{row['Text ID']}.pdf\")\n",
    "        else:\n",
    "            logging.warning(f\"No PDF link found for Text ID {row['Text ID']}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing row {index}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc51823-9930-4524-a2c0-590f03228a7e",
   "metadata": {},
   "source": [
    "## Tokenising the paragraphs of each article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd0b11-b0db-4c02-8249-ac1ec55cb16c",
   "metadata": {},
   "source": [
    "### Manual inspection and clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff330bf-9a04-4082-a502-f5bfc2fbb856",
   "metadata": {},
   "source": [
    "Inspect each article in `TXT` format and:\n",
    "- Remove titles and subtitles\n",
    "- Remove headers and footers\n",
    "- Remove elements such as tables, figures, references and appendices\n",
    "- Separate sets of lines that constitute paragraphs with an empty line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377ed5f-c4d0-4d93-bb03-26ce3ecae040",
   "metadata": {},
   "source": [
    "### Merging lines into paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e12f69-5f2b-4a1f-8105-48417217681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 316/316 [00:00<00:00, 708.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setting up logging\n",
    "logging.basicConfig(\n",
    "    filename = f\"{output_directory}/paragraph_tokenise_log.txt\",\n",
    "    level = logging.INFO,\n",
    "    format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Defining a function to tokenise the paragraphs of each article\n",
    "def paragraph_tokenise(text):\n",
    "    lines = text.split('\\n')\n",
    "    paragraphs = []\n",
    "    paragraph = ''\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            cleaned_line = ' '.join(line.split())  # Remove extra spaces within the line\n",
    "            paragraph += ' ' + cleaned_line.strip()  # Join subsequent lines into a paragraph\n",
    "        else:\n",
    "            paragraphs.append(paragraph.strip())  # If there is an empty line, the paragraph consolidated so far is added to the list of paragraphs\n",
    "            paragraph = ''  # The paragraph variable is cleared out\n",
    "    \n",
    "    if paragraph:\n",
    "        paragraphs.append(paragraph.strip())  # The last paragraph is added to the list of paragraphs\n",
    "    \n",
    "    tokenised_paragraphs = '\\n'.join(paragraphs)  # The list of paragraphs is compiled into a text with each paragraph as a separate line\n",
    "    \n",
    "    return tokenised_paragraphs\n",
    "\n",
    "# Defining a function to read the content of a TXT file\n",
    "def read_txt_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Defining a function to save the paragraph-tokenised articles into TXT files\n",
    "def save_paragraph_tokenised_file(output_text_content, output_file):\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as output_txt_file:\n",
    "            output_txt_file.write(output_text_content)\n",
    "        logging.info(f\"Successfully saved tokenised file: {output_file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving file {output_file}: {e}\")\n",
    "\n",
    "# Iterating through each row in the DataFrame and add the text content\n",
    "for index, row in tqdm(df_scielo_preprint_preChatGPT_en.iterrows(), total=df_scielo_preprint_preChatGPT_en.shape[0], desc='Processing files'):\n",
    "    text_id = row['Text ID']\n",
    "    txt_file_path = os.path.join(output_directory, f\"{text_id}.txt\")\n",
    "    if os.path.exists(txt_file_path):\n",
    "        text_content = read_txt_file(txt_file_path)\n",
    "        if text_content:\n",
    "            paragraph_tokenised_text_content = paragraph_tokenise(text_content)\n",
    "            save_paragraph_tokenised_file(paragraph_tokenised_text_content, f\"{output_directory}/{text_id}_tokenised.txt\")\n",
    "    else:\n",
    "        logging.warning(f\"File not found: {txt_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9107c-2a2f-40d4-a076-f44a1c700b13",
   "metadata": {},
   "source": [
    "## Adding the column `Text Paragraphs` with the text extracted from each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51830bb-70fc-4485-823b-c7d123eaf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the content of a TXT file\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Iterating through each row in the DataFrame and add the text content\n",
    "texts = []\n",
    "for index, row in df_scielo_preprint_preChatGPT_en.iterrows():\n",
    "    text_id = row['Text ID']\n",
    "    txt_file_path = os.path.join(output_directory, f\"{text_id}_tokenised.txt\")\n",
    "    if os.path.exists(txt_file_path):\n",
    "        text_content = read_txt_file(txt_file_path)\n",
    "    else:\n",
    "        text_content = None  # or you can set it to an empty string or any default value\n",
    "    texts.append(text_content)\n",
    "\n",
    "# Add the 'Text Paragraphs' column to the DataFrame\n",
    "df_scielo_preprint_preChatGPT_en['Text Paragraphs'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fd5cf-c14a-489d-9fce-ebce31015edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38e1da6-c54a-4b57-bcf5-3c695db12df9",
   "metadata": {},
   "source": [
    "## Exporting to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca417161-137c-4034-8b99-7ead215b0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en.to_json(f\"{output_directory}/scielo_erpp_pp.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e486130-8f97-4d45-a781-7720bd03a917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
