{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 3_2 - eyamrog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc807bb-6cbf-4b7c-ae5b-b70cf7fce407",
   "metadata": {},
   "source": [
    "The aim of this phase is to design a solution of text revision using ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685d8b0-7715-45a6-9489-2d3db9b346c8",
   "metadata": {},
   "source": [
    "## Required Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e16e73-b1b9-4838-8cce-a29dc300868e",
   "metadata": {},
   "source": [
    "- openai\n",
    "- pandas\n",
    "- python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa922755-c4d6-4008-9aad-d35e33b18ed7",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ebcaf3-5b41-474c-9394-ebc8bec9005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd82a71-ff9c-4e3c-9f7f-f7168a0b7918",
   "metadata": {},
   "source": [
    "## Defining input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7520b-1da6-450c-8c74-e424c1ead951",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'cl_st1_ph31_eyamrog'\n",
    "output_directory = 'cl_st1_ph32_eyamrog'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621c7d9-1a7b-4ea4-89ff-c3479b468fdc",
   "metadata": {},
   "source": [
    "## Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8dd16-0676-4e83-8867-0e676890b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the output directory already exists. If it does, do nothing. If it doesn't exist, create it.\n",
    "if os.path.exists(output_directory):\n",
    "    print('Output directory already exists.')\n",
    "else:\n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "        print('Output directory successfully created.')\n",
    "    except OSError as e:\n",
    "        print('Failed to create the directory:', e)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fad843-1ce9-4ea9-9f42-421dfe471266",
   "metadata": {},
   "source": [
    "## Configuring logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b4fff-628d-4707-ac74-c8d5dc5bece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to write to a file\n",
    "logging.basicConfig(\n",
    "    filename = f\"{output_directory}/chatgpt_review_log.txt\",\n",
    "    level = logging.INFO,\n",
    "    format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc346c15-46b9-4e1d-9fbc-d2c03f146504",
   "metadata": {},
   "source": [
    "## Preparing data for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a7f80a-fee0-487f-b313-9543a0ddb014",
   "metadata": {},
   "source": [
    "### Importing the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e583f-797c-4264-9504-fd82194ce67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en = pd.read_json(f'{input_directory}/test_erpp_pp.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ebf24-16df-494f-8641-fb110867b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92a5ed-5739-4d02-b775-4feb7753d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en['Submitted'] = pd.to_datetime(df_scielo_preprint_preChatGPT_en['Submitted'], unit='ms')\n",
    "df_scielo_preprint_preChatGPT_en['Posted'] = pd.to_datetime(df_scielo_preprint_preChatGPT_en['Posted'], unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9942da10-5398-43ee-a482-fe7dbac520e8",
   "metadata": {},
   "source": [
    "### Replacing unnecessary spaces with a single space"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c64517e-4921-4fa4-a5e3-85097599baa0",
   "metadata": {},
   "source": [
    "# Function to replace multiple spaces with a single space\n",
    "def replace_multiple_spaces(text):\n",
    "    return re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "# Applying the function to the 'Text' column\n",
    "df_scielo_preprint_preChatGPT_en['Text'] = df_scielo_preprint_preChatGPT_en['Text'].apply(replace_multiple_spaces)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e7513d0-f8ca-462e-829f-9117d73850a6",
   "metadata": {},
   "source": [
    "df_scielo_preprint_preChatGPT_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4894c4-3cd5-4c16-981f-42035497a1fe",
   "metadata": {},
   "source": [
    "## Loading all environment variables from `.env` into `os.environ`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283263e5-a464-4baa-9ae2-de0e82f13836",
   "metadata": {},
   "source": [
    "Create the `.env` file with the required `OPENAI_API_KEY` prior to running the following cell.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02061a-4528-4daf-943e-cff5d6cac1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c385a353-a0b2-4a02-8eac-b10f6f82da30",
   "metadata": {},
   "source": [
    "## Importing the required programme variables from the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee57760-cf35-4205-ab1c-595dbcea6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_API_KEY', '')\n",
    "assert openai.api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5f607-4c03-41d0-b99d-d932129ac74f",
   "metadata": {},
   "source": [
    "## Defining a function to query ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fb56b-0a2b-49fc-9afc-d354063ad6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to query ChatGPT with exponential backoff\n",
    "def get_completion(prompt, model='gpt-3.5-turbo', max_retries=5):\n",
    "    client = openai.OpenAI()\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except openai.error.RateLimitError as e:\n",
    "            wait_time = 2 ** attempt  # Exponential backoff\n",
    "            logging.warning(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error querying ChatGPT: {e}\")\n",
    "            return None\n",
    "    logging.error(\"Max retries exceeded.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becc2c36-6566-4fc1-8037-270e5add43d6",
   "metadata": {},
   "source": [
    "## Getting improved paragraphs from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334dd9d-7de7-47b5-9262-3d855b185705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the ChatGPT prompt template\n",
    "prompt_template = 'Dear ChatGPT, would it be possible for you to improve the writing of the following passage of a research article considering the generally accepted standards of English for Academic Purposes? Please keep each improved passage within a single paragraph - do not split it into multiple paragraphs. OK?\\n'\n",
    "\n",
    "# Defining a function to improve text using ChatGPT\n",
    "def improve_text(text):\n",
    "    paragraphs = text.split('\\n')  # Split text into paragraphs\n",
    "    improved_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "        prompt = prompt_template + paragraph\n",
    "        improved_paragraph = get_completion(prompt)\n",
    "        if improved_paragraph:\n",
    "            improved_paragraphs.append(improved_paragraph)\n",
    "        else:\n",
    "            improved_paragraphs.append(paragraph)  # Keep original if there's an error\n",
    "        time.sleep(15)  # Fixed delay between queries\n",
    "    return '\\n'.join(improved_paragraphs)\n",
    "\n",
    "# Applying the function to the 'Text' column with progress indication\n",
    "improved_texts = []\n",
    "for text in tqdm(df_scielo_preprint_preChatGPT_en['Text'], desc=\"Processing texts\"):\n",
    "    improved_texts.append(improve_text(text))\n",
    "\n",
    "df_scielo_preprint_preChatGPT_en['Text ChatGPT'] = improved_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fcc327-4655-4233-90c1-fea8403536b7",
   "metadata": {},
   "source": [
    "### Replacing unnecessary spaces with a single space"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21cb4488-1bc3-4859-8581-9d33970667ee",
   "metadata": {},
   "source": [
    "# Function to replace multiple spaces with a single space\n",
    "def replace_multiple_spaces(text):\n",
    "    return re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "# Applying the function to the 'Text' column\n",
    "df_scielo_preprint_preChatGPT_en['Text ChatGPT'] = df_scielo_preprint_preChatGPT_en['Text ChatGPT'].apply(replace_multiple_spaces)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a37e0de-912e-4af9-ae5e-7248e793ea99",
   "metadata": {},
   "source": [
    "df_scielo_preprint_preChatGPT_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53608b5-1082-4bf7-809f-7a7ab33294bc",
   "metadata": {},
   "source": [
    "## Exporting each article processed by ChatGPT to individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eef97-1a7d-4e9e-bc83-83706db078f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_scielo_preprint_preChatGPT_en.iterrows():\n",
    "    file_name = f\"{output_directory}/{row['Text ID']}.txt\"\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(row['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d58f0-2330-43ff-a8c7-90e6b19700b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_scielo_preprint_preChatGPT_en.iterrows():\n",
    "    file_name = f\"{output_directory}/{row['Text ID']}_chatgpt.txt\"\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(row['Text ChatGPT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daebc28-430f-4990-8205-9e999dab8c33",
   "metadata": {},
   "source": [
    "### Exporting to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ed787-55e7-4825-8fc6-1d957d8e863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scielo_preprint_preChatGPT_en.to_json(f\"{output_directory}/test_chatgpt_erpp_pp.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8066d-256e-4257-8419-1ab7b459c655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
