{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 1 - eyamrog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc807bb-6cbf-4b7c-ae5b-b70cf7fce407",
   "metadata": {},
   "source": [
    "The aim of this phase is to determine the basic usage of the following Python libraries:\n",
    "\n",
    "- `pypdf` and `PyMUPdf` for PDF document scraping\n",
    "- `python-docx` for DOCX document scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50976282-3c48-4a64-a25c-0575bf379f25",
   "metadata": {},
   "source": [
    "## What is `pypdf`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60552836-4e24-45fa-a537-692248055ea1",
   "metadata": {},
   "source": [
    "`pypdf` is a free and open-source pure-python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files. It can also add custom data, viewing options, and passwords to PDF files. pypdf can retrieve text and metadata from PDFs as well.\n",
    "\n",
    "Please refer to:\n",
    "- [Scrape Data from PDF: A Comprehensive Guide for Data Analysts](https://parser.expert/blog/scrape-data-from-pdf)\n",
    "- [How to Extract Data from PDF Files with Python](https://www.freecodecamp.org/news/extract-data-from-pdf-files-with-python/)\n",
    "- [Extracting Semi-Structured Data from PDFs on a large scale](https://github.com/janedoesrepo/pdfreader/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfaf327-f54a-4496-b837-e91bf330e28e",
   "metadata": {},
   "source": [
    "## What is `PyMuPDF`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b333cf-4c16-4823-a243-9fbadf62c69a",
   "metadata": {},
   "source": [
    "`PyMuPDF` is a high performance Python library for data extraction, analysis, conversion & manipulation of PDF (and other) documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cd2ba-f9bd-485e-af60-5fcb3ce87231",
   "metadata": {},
   "source": [
    "## What is `python-docx`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d6fb4-3ef0-44a1-a313-d200e2853d88",
   "metadata": {},
   "source": [
    "`python-docx` is a Python library for reading, creating, and updating Microsoft Word 2007+ (.docx) files.\n",
    "\n",
    "Please refer to:\n",
    "- [5 Best Ways to Read Microsoft Word Documents with Python](https://blog.finxter.com/5-best-ways-to-read-microsoft-word-documents-with-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685d8b0-7715-45a6-9489-2d3db9b346c8",
   "metadata": {},
   "source": [
    "## Required Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e16e73-b1b9-4838-8cce-a29dc300868e",
   "metadata": {},
   "source": [
    "- pypdf\n",
    "- PyMuPDF\n",
    "- python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa922755-c4d6-4008-9aad-d35e33b18ed7",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ebcaf3-5b41-474c-9394-ebc8bec9005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "import pymupdf\n",
    "from docx import Document\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66294f4c-26b8-4fcc-8b3a-926cda1ef39f",
   "metadata": {},
   "source": [
    "## Defining input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be889fb4-e365-4f82-a951-da7a6e3b4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'cl_st1_ph1_eyamrog'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e503e-8762-482c-a0e5-25dbd5331ad0",
   "metadata": {},
   "source": [
    "## Creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65fd7eaf-fec8-4aea-b905-d8bd9022c23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists.\n"
     ]
    }
   ],
   "source": [
    "# Check if the output directory already exists. If it does, do nothing. If it doesn't exist, create it.\n",
    "if os.path.exists(output_directory):\n",
    "    print('Output directory already exists.')\n",
    "else:\n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "        print('Output directory successfully created.')\n",
    "    except OSError as e:\n",
    "        print('Failed to create the directory:', e)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e9074-4c80-4bf5-9748-14a59689048c",
   "metadata": {},
   "source": [
    "## `pypdf` PDF scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a813756-d796-488f-98c0-963cfa7b290d",
   "metadata": {},
   "source": [
    "### Setting required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad68492-cb17-4f75-876a-a6e277138e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = f'{output_directory}/monte_mor_1.pdf'\n",
    "output_txt = f'{output_directory}/monte_mor_1_pypdf.txt'\n",
    "page_num = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41bab9-dcc3-4e88-a9d0-07dd433c8145",
   "metadata": {},
   "source": [
    "### Sampling pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c5d6e5f-cef1-4c5d-b6fb-ef9b39a1b7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universidad Nacional de Colombia - Facultad de Ciencias Humanas – Bogotá \\nwww.revistamatices.unal.edu.co \\n \\nRevista Electrónica Matices en Lenguas  Extranjeras No. 2, Diciembre 2008 \\n 1 \\n Critical Literacies, Meaning Ma king and New Epistemological \\nPerspectives \\n \\nWalkyria Monte Mór \\uf02a \\nwalsil@uol.com.br \\nUniversity of São Paulo, Brazil \\n \\nThis article presents a research analysis in which Brazilian university students were the subjects of \\nresearch in regard to their reading of cinema images. The analysis discusses the way the meanings are \\nconstructed by these students and reflects on interpretation and meaning construction in accordance with new \\nepistemological perspectives that have been postulated recently (Morin, 1998; Lankshear & Knobel, 2003). It, \\nthus, considers the present needs of the multimodal and hypertextual communication approached in the \\nmultiliteracy studies (Cope & Kalantzis, 2000), and the university preparation for a critical and participative cultural and social practice (Castells, 1999).   \\nKey words:  Meaning making, critical literacy, digital epistemologies  \\n \\nEste artículo presenta un análisis investigativo en el cual alumnos de una universidad brasileña \\nfueron entrevistados sobre sus lecturas de imágenes de cine. El análisis discute la manera en que los \\nsignificados son construidos por estos alumnos y reflexiona sobre la interpretación y la construcción de los \\nmismos, según la nueva perspectiva epistemológica que ha sido postulada recientemente (Morin 1998; \\nLankshear & Knobel 2003).  Considera las necesidades presentes de la comunicación multimodal e \\nhipertextual imbuida en los estudios de multiletramento (Cope & Kalantzis, 2000), como así también la \\npreparación universitaria para una práctica social crítica y participativa (Castels, 1999). \\nPalabras Clave: Creación de significados, lecto-escritura crítica, epistemologías digitales \\n \\n \\n                                                 \\n\\uf02a Walkyria Monte Mór  is a professor at the University of São Paulo, Brazil. She has a master’s degree in Philosophy of Education and \\na Doctor’s Degree in Language and Education. She is co-author of the National Curriculum for the Teaching of Foreign Languages in \\nSecondary Schools in Brazil (2006).  . '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_reader = pypdf.PdfReader(pdf_path)\n",
    "page = pdf_reader.pages[page_num]\n",
    "text = page.extract_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8b26e-fc19-42b8-940d-e212372e25a3",
   "metadata": {},
   "source": [
    "### Scraping the entire document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd49b61a-bec3-480f-82db-b7eba4cccf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF scraped successfully!\n"
     ]
    }
   ],
   "source": [
    "def scrape_pdf(pdf_path, output_txt):\n",
    "    # Creating a PdfReader object\n",
    "    pdf_reader = pypdf.PdfReader(pdf_path)\n",
    "    \n",
    "    # Initialising an empty string to store the text\n",
    "    text = ''\n",
    "    \n",
    "    # Iterating through all the pages and extract text\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    # Writing the extracted text to a text file in UTF-8 encoding\n",
    "    with open(output_txt, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text)\n",
    "\n",
    "scrape_pdf(pdf_path, output_txt)\n",
    "print('PDF scraped successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc956dca-9b59-4ff5-807c-e0e0d3f209aa",
   "metadata": {},
   "source": [
    "## `PyMuPDF` PDF scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f11f0-ac9c-4054-8759-8aa1c03b6429",
   "metadata": {},
   "source": [
    "### Setting required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00dbd02d-008b-46e8-bd0c-085986b8d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = f'{output_directory}/monte_mor_1.pdf'\n",
    "output_txt = f'{output_directory}/monte_mor_1_PyMuPDF.txt'\n",
    "page_num = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80eeadb-a401-4ecf-a356-bca975cfe809",
   "metadata": {},
   "source": [
    "### Sampling pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a11fe05a-0744-43dd-8b18-9d0aeea0e7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universidad Nacional de Colombia - Facultad de Ciencias Humanas – Bogotá \\nwww.revistamatices.unal.edu.co \\n \\nRevista Electrónica Matices en Lenguas Extranjeras No. 2, Diciembre 2008 \\n 1\\n \\n \\nCritical Literacies, Meaning Making and New Epistemological \\nPerspectives \\n \\nWalkyria Monte Mór \\uf02a \\nwalsil@uol.com.br \\nUniversity of São Paulo, Brazil \\n \\nThis article presents a research analysis in which Brazilian university students were the subjects of \\nresearch in regard to their reading of cinema images. The analysis discusses the way the meanings are \\nconstructed by these students and reflects on interpretation and meaning construction in accordance with new \\nepistemological perspectives that have been postulated recently (Morin, 1998; Lankshear & Knobel, 2003). It, \\nthus, considers the present needs of the multimodal and hypertextual communication approached in the \\nmultiliteracy studies (Cope & Kalantzis, 2000), and the university preparation for a critical and participative \\ncultural and social practice (Castells, 1999).   \\nKey words: Meaning making, critical literacy, digital epistemologies  \\n \\nEste artículo presenta un análisis investigativo en el cual alumnos de una universidad brasileña \\nfueron entrevistados sobre sus lecturas de imágenes de cine. El análisis discute la manera en que los \\nsignificados son construidos por estos alumnos y reflexiona sobre la interpretación y la construcción de los \\nmismos, según la nueva perspectiva epistemológica que ha sido postulada recientemente (Morin 1998; \\nLankshear & Knobel 2003).  Considera las necesidades presentes de la comunicación multimodal e \\nhipertextual imbuida en los estudios de multiletramento (Cope & Kalantzis, 2000), como así también la \\npreparación universitaria para una práctica social crítica y participativa (Castels, 1999). \\nPalabras Clave: Creación de significados, lecto-escritura crítica, epistemologías digitales \\n \\n \\n                                                 \\n\\uf02a Walkyria Monte Mór is a professor at the University of São Paulo, Brazil. She has a master’s degree in Philosophy of Education and \\na Doctor’s Degree in Language and Education. She is co-author of the National Curriculum for the Teaching of Foreign Languages in \\nSecondary Schools in Brazil (2006).  \\n. \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = pymupdf.open(pdf_path)\n",
    "page = doc[page_num]\n",
    "text = page.get_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa221d80-ef86-48ff-bf1c-ba58b7365497",
   "metadata": {},
   "source": [
    "### Scraping the entire document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d5b9b2-85ed-445e-9bac-98beb8c3df20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF scraped successfully!\n"
     ]
    }
   ],
   "source": [
    "def scrape_pdf(pdf_path, output_txt):\n",
    "    # Opening the PDF file\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    \n",
    "    # Initialising an empty string to store the text\n",
    "    text = ''\n",
    "    \n",
    "    # Iterating through all the pages and extract text\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    # Writing the extracted text to a text file in UTF-8 encoding\n",
    "    with open(output_txt, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text)\n",
    "\n",
    "scrape_pdf(pdf_path, output_txt)\n",
    "print('PDF scraped successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa1b21-8e91-4e52-a768-a92d4700aa15",
   "metadata": {},
   "source": [
    "## `python-docx` DOCX scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef8f3d-7d00-42ea-9a0c-377bd1b84e74",
   "metadata": {},
   "source": [
    "### Setting required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6470ff8a-9ab2-49d8-a637-95fad14cf68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_path = f'{output_directory}/yamada_1.docx'\n",
    "output_txt = f'{output_directory}/yamada_1_python-docx.txt'\n",
    "paragraph_num = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1461d2e9-055c-443c-8dbe-c919b981480c",
   "metadata": {},
   "source": [
    "### Sampling paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0775eeda-4662-413c-be8b-dc2c438fd540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE RELEVANCE OF AI-POWERED TOOLS IN THE ENGLISH ACADEMIC WRITING OF BRAZILIAN SCHOLARS IN APPLIED LINGUISTICS AND IN THE VISUALISATION OF RESEARCH DATA'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document(docx_path)\n",
    "paragraph = doc.paragraphs[paragraph_num]\n",
    "text = paragraph.text\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197bad7-947b-45ea-ab12-bb75c2565424",
   "metadata": {},
   "source": [
    "### Scraping the entire document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7a7db1-0c6f-4309-baaa-651546c42f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCX scraped successfully!\n"
     ]
    }
   ],
   "source": [
    "def scrape_docx(docx_path):\n",
    "    # Opening the DOCX file\n",
    "    doc = Document(docx_path, output_txt)\n",
    "\n",
    "    # Initialising an empty string to store the text\n",
    "    text_list = []\n",
    "\n",
    "    # Iterating through all the paragraphs and extract text\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text_list.append(paragraph.text)\n",
    "\n",
    "    text = '\\n'.join(text_list)\n",
    "    \n",
    "    # Writing the extracted text to a text file in UTF-8 encoding\n",
    "    with open(output_txt, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text)\n",
    "\n",
    "scrape_docx(docx_path, output_txt)\n",
    "print('DOCX scraped successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9add2e0-500b-448f-82b2-08b51c85efe7",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b79bc3-8d1c-4a9e-a18e-b0a980832fb3",
   "metadata": {},
   "source": [
    "Comparing the results, `pypdf` introduces spaces between and in the middle of words that should not exist. It does not happen with `PyMuPDF`, which makes it perform better in this aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4186c-55bc-4be1-9d6c-d0c6b140e4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
