This article was funded by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES, Brazil) (Finance Code 001), the Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq, Brazil), and the Universidade Federal de Alagoas (UFAL, Brazil).
Text mining and related analytics emerge as a technological approach to support human activities in extracting useful knowledge through texts in several formats. From a managerial point of view, it can help organizations in planning and decision-making processes, providing information that was not previously evident through textual materials produced internally or even externally. In this context, within the public/governmental scope, public security agencies are great beneficiaries of the tools associated with text mining, in several aspects, from applications in the criminal area to the collection of people's opinions and sentiments about the actions taken to promote their welfare. This article reports details of a systematic literature review focused on identifying the main areas of text mining application in public security, the most recurrent technological tools, and future research directions. The searches covered four major article bases (Scopus, Web of Science, IEEE Xplore, and ACM Digital Library), selecting 194 materials published between 2014 and the first half of 2021, among journals, conferences, and book chapters. There were several findings concerning the targets of the literature review, as presented in the results of this article.
Text mining and analytics is a trendy field both from the research point of view and as a practical application in organizations, being involved with the discovery of knowledge in textual bases and the subsequent analyses that can be applied to texts within a collection. Any organization can benefit from the associated tools, regardless of whether it is private or public. In the public and governmental context, managers can apply these tools to support planning processes and decision-making, using, for example, information extracted from texts extracted from the social web containing opinions coming directly from service users.
It is here that the context of public security can be inserted, using text mining tools to support investigative processes, detection or prediction of criminal activities, prevention of public events harmful to citizens, or even to collect opinions from these citizens about security actions that are already being applied. According to their core functionality, text mining-related approaches contain techniques and methods that can be categorized into information retrieval and extraction, document clustering and classification, natural language processing, and web mining (Talib et al., 2016; Zainol et al., 2018).
Each approach includes different applications on issues related to public security. For instance, Information retrieval and extraction tasks can be applied in the mining process for digital investigation systems to obtain the most relevant texts or documents according to a specific investigational subject (Gowri et al., 2014). Another example is selecting unstructured criminal judgment texts to extract information necessary to support lawyers and judges in their activities (Iftikhar et al., 2019).
The clustering and classification of texts consist of applying techniques capable of creating groups or applying labels to texts according to similar classes or categories (Park et al., 2019). Both tasks were applied by Kuang et al. (2017) in their text mining application to discover meaningful latent crime classes using textual records of crime events. In another example, Das and Das (2019) applied a graph-based clustering technique to discover crime reports' labels based on extracted paraphrasing from large untagged crime corpora. Thao et al. (2017) applied an approach to classifying landing and distribution domains, which were essential components for analyzing cyberattack types.
Natural language processing is a vast area dedicated to analyzing and synthesizing spoken and written language using computers (Jackson & Moulinier, 2002). Another concept that can be given for natural language processing is that it attempts to extract a fuller meaning representation from texts, using linguistic concepts such as part-of-speech and grammatical structure (Kao & Poteet, 2007). It comprises many techniques widely used in text mining to support several other tasks, such as those mentioned above. However, according to Sankar et al. (2020), the essence of natural language processing is identifying the language in a text and applying rules to identify and extract useful information.
In their study, Gravanis et al. (2019) provide an example of fake news detection, proposing a natural language processing approach that uses linguistic-based features combined with machine learning. Their conclusions establish that this type of approach provides publishers with a basis for determining which content should be best evaluated, avoiding publishing untrue information. This note by the authors only reinforces the support that text mining provides when the human analytical capacity fails to detect elements or even events capable of causing damage; in this case, it is also related to more specific issues of cybersecurity involving people using online platforms to communicate and share information.
Web mining is defined as a set of text mining techniques that learn how information is distributed across the Internet through characterization and classification of web pages, enabling discovering how these pages are interrelated (Han et al., 2011). Three types of web mining were reviewed by Kavita et al. (2016) and Kumar and Palanisamy (2008), including content mining, structure mining, and usage mining. These methods were reinforced by de la Torre et al. (2018), who set web mining, or "web data mining," as being equivalent to "text mining on web documents." Still, within this approach, the social web contains a wide range of data to be explored, enabling, for example, the users' sentiment analysis about a given topic (Costa et al., 2012). The works by Anwar and Abulaish (2014a) and Anwar and Abulaish (2014b) contain examples of a web mining application dedicated to retrieving relevant information from webpages for the detection of namesakes, a relevant cybersecurity task supporting the disambiguation of people with the same name.
The literature presented in this introduction exemplifies the wide variety of applications that text mining offers for public security and related matters, supporting a systematic literature review to identify opportunities for new research.
The purpose of this text is to present the details about the results of a systematic literature review on text mining applied to public security, corroborating the validity and importance of associated tools to assist in decisions and actions of public security agencies. The rest of this article is structured as follows: Section 2 details the methodology applied for the systematic literature review; Section 3 presents the details of the review results; Section 4 contains the conclusion of this work.
This section provides details about the systematic literature review process, including explanations about: search criteria, filtering, full papers assessment, information extraction, and software used to support analysis. The guidelines applied for the review process were presented by Kitchenham and Charters (2007), following the workflow indicated in Figure 1.
This entire procedure was dedicated to extracting and selecting literature aiding in identifying a) the main areas of application of text mining in public security; b) the most recurrent text mining technologies in public security-related issues, according to selected literature; and c) open opportunities and challenges for the application of text mining in public security, according to future directions pointed out in the most recent literature. The following sections will describe each part of the workflow in Figure 1.
The literature search was limited by the following criteria: a) works only in English, b) journal articles, complete conference papers and book chapters, and c) publication dates between 2014 and 2021.
For selection criterion c), the period of eight years was defined by considering two aspects of the literature. The first was to filter the most recent literature published on the themes focused on this work. The second concerns the number of works published on the theme because 70.62% is concentrated between 2017 and 2020. The previous three years (2014, 2015, and 2016) add up to only 27.84% of the works, and the year 2021 completes the total number of selected works (representing only 1.55% of them) since the literature extraction was performed before this year had ended.
The search queries considered the following Boolean condition: ("text mining") AND ("public security" OR "crime" OR "terrorism" OR "piracy" OR "drug trafficking" OR "arms trafficking" OR "human trafficking" OR "sexual exploitation" OR "prostitution" OR "pedophilia" OR "rape" OR "homicide" OR "murder" OR "femicide" OR "infanticide" OR "bodily injury" OR "extortion" OR "theft" OR "robbery" OR "assault" OR "burglary" OR "property damage" OR "misappropriation" OR "money laundering" OR "embezzlement" OR "stellionate" OR "receiving" OR "kidnapping" OR "defamation" OR "cybercrime").
The crime-related terms in the query were taken from the Brazilian Penal Code (Decree-Law No. 2848 / 1940), which is still the current penal code in Brazil, updated by a series of other legal provisions over the years and defines all possible penalties for the related crimes.
To corroborate these terms, the American Model Penal Code also provides descriptions of several of these terms so that others are either variations or, even if not included, are related to the present ones, as can be seen in Robinson and Dubber (2007). Examining the crime information related to the Crown Prosecution Service1 (England and Wales), these terms are also corroborated by the several categories listed: domestic abuse, drug offenses, fraud, and economic crime, hate crime, sexual offenses, terrorism, verbal abuse, violent crime, and even cybercrime. As a final resource to corroborate the presence of these terms, Brazilian Jurisprudence2 was also consulted through documents of court sentences on crimes.
This condition was applied to four databases, considering the specific formats of each one: Scopus, Web of Science, IEEE Xplore, and ACM Digital Literature.
After retrieving the literature from each database, sequential filters were applied to eliminate duplicates, resulting in the exclusion of 178 works, leaving for the subsequent analysis only those related to the theme through the direct screening of titles and abstracts. The titles and abstracts screening resulted in the exclusion of 376 works for the information extraction phase.
The information extraction strategy was based on the manual search for objectives, methodology, applications, and other indications about what each selected works applied. A spreadsheet was maintained to include information about authorship, publication channel name, primary objectives and purposes, related problems, synthesis of the methods, techniques, technologies used, key applications, keywords, type of work, publication year, and key terms related to the techniques and technologies. Also, a final field was included to identify proposals for future work if they are described in the publication.
During the assessment of full papers for extracting information, 58 papers were excluded as out of the review’s scope: (i) for not adding relevant information to the research since they were literature reviews, although focusing on themes related to text mining in the public security; (ii) because they were in a language other than English; and (iii) because they applied other types of analysis in public security that did not involve text mining.
Thus, this phase included generating a spreadsheet containing summaries of the 194 selected works containing relevant information following the process outlined in the literature selection process. All the information extraction from the selected works was performed manually by reading the texts and recording the desired information in the spreadsheet. Among these 194 works, just 92 entered for the opportunities and challenges extraction since they contained directions for future research.
Elsevier's Mendeley software was leveraged for the screening process and assisted in the insertion of citations creation of references. A Python script was applied to make counting create charts and tables from the spreadsheet with information extracted from the literature. Web application WordItOut3 was used to obtain the word cloud with the most frequent terms related to the technologies and techniques found in the literature.
The information extracted from the 194 selected works is available in a spreadsheet within a publicly open repository at GitHub4. This spreadsheet contains the information of interest for each selected article, as described in Figure 1.
This section contains details about the literature review results, separating them according to the three items defined in the previous section:
a) The main areas of application of text mining in public security.
b) The most recurrent text mining technologies in public security.
c) The open opportunities and challenges for text mining in public security based on future directions in the most recent literature (2018 to the first semester of 2021).
For a complete listing of journals, conferences, and books, with the related counts for each channel, see Tables A1, A2, and A3 in Appendix A.
Literature provided an understanding of the main areas related to public security demanding text mining applications. Listing from the area with the greatest number of selected works to the one with fewer works: cybersecurity (62 works), general crime detection/prediction (29), fraud detection (22), terrorism detection (16), cyberbullying detection (14), digital/cyber forensics (14), support to the judiciary power (6), support to law enforcement agencies' actions (6), crimes' victims support (4), sex-related crimes detection (4), drug-related crimes detection (3), espionage detection (3), information security (3), software piracy detection (2), civil unrest detection (2), drug-related crimes detection and weapons' trafficking detection (1), weapons' trafficking detection (1), armed conflicts solution (1), and violence against woman analysis (1). Note that there is one work in an area combining “drug-related crimes detection and weapons' trafficking detection”.
The tables below present the works according to their publication years according to these application areas. Table 1 contains the details of the "Cybersecurity" area.
The Cybersecurity area had the largest number of works selected in 2017 and 2018, with the same amount, followed by 2019. These three years represent 56.45% of the total within this area. Table 2 contains the details in the "General crime detection/prediction" area.
In the "General crime detection/prediction" area, 2019 concentrated the largest number of selected works, followed by 2017 and 2018, each with the same amount. These three years represent 65.52% of the total within this area. Table 3 demonstrates the works selected for the "Fraud detection" area.
In "Fraud detection", 2017 concentrated the largest number of selected works, representing 27.27% of the total in this area. The years 2014, 2016, 2018, 2019, and 2020 had the same amount of work, representing 68.18% within the area. Table 4 contains the details of selected literature from the "Terrorism detection" area.
In "Terrorism detection", 2018 had the highest number of works, followed by 2017, totaling 56.25% of all works in this area. Table 5 contains details on the "Cyberbullying detection" area.
In "Cyberbullying detection", 2020 presented the highest number of selected works, followed by 2017, with these two years adding up to 50% of the total in this area. Table 6 separates the selected works within the "Digital/Cyber forensics" area.
The year 2016 concentrated the largest number of works selected in the "Digital/Cyber forensics", representing 35.71% of the total in this area. The years 2014, 2015, 2017, and 2019 had the same amount of work, adding up to 57.14% of the works in this area. Table 7 concerns the "Support to the Judiciary power" area.
In "Support to the Judiciary power", the year 2019 concentrated 66.67% of the works in the area. Each of the two other years that appeared, 2015 and 2020, has only one selected work. Table 8 shows the breakdown of the "Support to Law Enforcement agencies actions" area.
In "Support to Law Enforcement agencies actions", 2019 and 2020 had the same amount of work, representing 66.67% of the total in this area. More than one area will be presented per table from the following table, as the sum of the totals of the areas that appear together does not exceed 10. Table 9 refers to "Crimes' victims support" and "Sex-related crimes ".
The "Crimes' victims support" area had 50% of its works in 2020, while the "Sex- related crimes detection" area concentrated 50% of its works in 2018. Table 10 contains the selected works from the "Drug-related crimes detection", "Espionage detection", and "Information security" areas.
While in "Drug-related crimes detection" every year had the same amount of work published, in "Espionage detection" and "Information security" the year 2016 had the largest amount of work.
In "Software piracy detection", only occurred the works by Kim et al. (2018) and Sarwar et al. (2019). In "Civil unrest detection" there were two works: one by Ning et al. (2016) and other by Wei et al. (2020). There was no prevalence of any year in these two areas with a greater amount of work.
The last four areas had only one work each, in specific years: Al-Nabki et al. (2020) in the communal area "Drug-related crimes detection and Weapons' trafficking detection"; Saini and Bansal (2019) in Weapons' trafficking detection; Correa et al. (2018) in "Armed conflicts solution"; and Gil et al. (2018) in "Violence against woman analysis". The following section will present the details of techniques related to text mining found in the selected literature, crossing these techniques with the areas to determine the most recurrent ones by application area.
This section will separate the most frequent terms referring to techniques and technologies according to each application area in public security. For "Cybersecurity", the most frequent technologies were Python and R programming languages, the Scikit-Learn and Natural Language Toolkit libraries, and the WEKA software. Regarding text mining techniques, those associated with machine learning are highlighted: Support Vector Machines, Decision Trees, Random Forests, and Naïve Bayes as the four most recurrent. There is also an emphasis on "term frequency-inverse document frequency" as one of the most frequent terms in the overall count.
In the "General crime detection/prediction" area, the most frequent technology was the Python language followed by the Natural Language Toolkit and RapidMiner, the latter a software dedicated to data mining. For techniques, those referring to machine learning were led by Naïve Bayes, followed by Support Vector Machines, Decision Trees, and Latent Dirichlet Allocation, to mention the most recurrent of this type. Term frequency-inverse document frequency shares with Naïve Bayes the rank of the second most frequent term. All other terms after the seventh position had only one occurrence for this area.
In the "Fraud detection" area, the most frequent technologies were Python, MatLab, and Scikit-Learn, and this time, the positions occupied were lower: Python sharing the sixth position with Random Forests and Named Entity Recognition; and MatLab and Scikit-Learn sharing the seventh position with eight other terms. Among the technologies mentioned, only MatLab is new compared to what has already been analyzed, being a proprietary platform for numerical analysis involving a dedicated programming language with the same name. Four machine learning techniques stand out: Support Vector Machines, Logistic Regression, Naïve Bayes, and Decision Trees, occupying the first, second, third, and fourth positions. Also, all other terms after the seventh position had only one occurrence for this area.
The terms extracted for "Terrorism detection" demonstrated a different trend compared to the areas previously explored concerning the frequency of technologies: the R language stands out, sharing the first position in the list with the techniques Naïve Bayes and term frequency-inverse document frequency. The other technology that appeared among the most frequent terms was Scikit-Learn, a library of techniques referring to the Python language. As mentioned, among machine learning techniques, Naïve Bayes appears first, followed by Support Vector Machines, Random Forests, and Decision Trees. Term frequency-inverse document frequency, while a natural processing language technique remains in the spotlight.
For the "Cyberbullying detection" area, two machine learning techniques are the first: Naïve Bayes and Support Vector Machines. In the second position, along with the Python language and the term document-frequency inverse frequency technique, another machine learning technique can be found: the k-Nearest Neighbors. Three other technologies appear, sharing the third position: LIBSVM, an open-source cross-platform library that can be used with several other data analysis tools; Scikit-Learn and RapidMiner.
Tables A6, A7, A8, A9, A10 and A11 in Appendix A contain some counts about techniques and technologies in the previously commented areas. The following paragraphs continue presenting details about the remaining areas, but there are no related tables since the number of records found is much lower than in the previous areas.
Latent Dirichlet allocation appears as the most frequent machine learning technique in the "Digital / Cyber forensics" area, followed by Support Vector Machines, which shares second place with Natural Language Toolkit, Python, and Named Entity Recognition.
The "Support to the Judiciary power" area presented only term frequency-inverse document frequency as a recurring term, appearing twice. All other terms were unique, with emphasis on technologies: Python, R, Perl, Gensim library for natural language processing (for use with Python language) and WinBugs software, dedicated to Bayesian statistical analysis applying the Markov Chain Monte Carlo technique, which also appears among the extracted terms for this specific area. Naïve Bayes and Named Entity Recognition, which have been frequent in all other areas explored so far, also deserve to be mentioned for this area.
The "Support to Law Enforcement agencies actions" area has four terms referring to the most frequent techniques and technologies, each appearing twice: Latent Dirichlet Allocation, R language, Document-Term Matrix, and Named Entity Recognition. The term Document-Term Matrix refers to a matrix containing the frequency of terms in a document, being a relevant textual data structure, for example, for the application of topic modeling techniques.
The "Crimes' victims support" area has a set of more frequent terms that are somewhat different from the previous areas: General Architecture for Text Engineering, Java Annotations Pattern Engine, Rule-Based Language Expression Patterns, dictionaries, and manual annotation, each one appearing twice. General Architecture for Text Engineering, Java Annotations Pattern Engine, and Rule-Based Language Expression Patterns were used in Karystianis et al. (2018) and Karystianis et al. (2019), the first being a text annotation and categorization framework; the second, a pattern comparison language used in combination with the first; the third, an implementation made for application in the knowledge-based system developed by the authors, based on term dictionaries.
The "Sex-related crimes detection" area did not have any term more frequent than the others, all of which presented only one occurrence. Noteworthy is the presence of the R language, the open-source and cross-platform library LIBLINEAR, containing linear classifiers such as Support Vector Machines and Logistic Regression. Among the techniques: k-Nearest Neighbors, Logistic Regression, and Support Vector Machines.
The same occurs in "Drug-related crimes detection", not having terms with more than one occurrence. Here they highlight technologies such as Python and R languages, Automap, and ORA software, the latter two used by Neumann and Sartor (2016). While Automap software is dedicated to text mining tasks, ORA is used for network construction. The presence of the latter software is consistent with the term Semantic Network Analysis found in the set referring to this area. Naïve Bayes, Logistic Regression, Support Vector Machines, and Random Forests also occur in this area.
In "Espionage detection", two techniques had two occurrences each: manual annotation and dictionaries. Fisher's Exact Test once appeared, referring to a well-known statistical test to compare different proportions for categorical variables. In the "Information security" area, no term was often higher than one. Here, the Python language and the Natural Language Toolkit can be mentioned among the technologies once again. A new technology emerged: the Openhangul API, used by Lee et al. (2016) for applying sentiment analysis.
In the "Software piracy detection" area, the only technology mentioned was WEKA, appearing only once. Of the machine learning techniques that recurrently appear in previously explored areas, only Random Forests occurred, and only once. Two other techniques that occurred once were: Weighted-Clustering-Coefficient and Graph-Based Static Birthmarking, both used by Sarwar et al. (2019). The Weighted-Clustering-Coefficient was applied to compute the similarity percentage between different computer programs under analysis, supporting the creation of the nodes in the Graph-Based Static Birthmarking technique.
Several techniques and technologies already presented were repeated in the “Civil unrest detection" area, but each with only one occurrence. Among the technologies, the Python language and its Gensim library stand out. Again, machine learning techniques stand out among those found: Naïve Bayes, Logistic Regression, Support Vector Machines, Adaptive Boosting, Extreme Gradient Boosting. There is an occurrence for the Word2Vec technique that consists of creating a textual features model to train classification models. All these techniques were employed by Wei et al. (2020).
The combination of areas "Drug-related crimes detection, Weapons' trafficking detection", as mentioned previously, presented only one related work, from which all terms were extracted. Al-Nabki et al. (2020) used the Python language and the Keras neural network library (written in Python), applying the Local Distance Neighbor Algorithm to recognize named entities that may be related to drug trafficking and illegal weapons sale through the Darkweb.
There was only one technology in the "Weapons' trafficking detection" area: the R Language, with one occurrence. Techniques such as Boosting, Decision Trees, Random Forests, Support Vector Machines reappear, each also with only one occurrence. There are new terms such as Cohen’s kappa Coefficient and Maximum Entropy, both with one occurrence and used by Saini and Bansal (2019). Cohen’s Kappa Coefficient was applied to check the agreement between two experts, and Maximum Entropy was used along with the other techniques mentioned earlier in this paragraph to perform classifications.
For the last two areas, "Armed conflicts solution" and "Violence against woman analysis", few techniques were detected, all with only one occurrence, since there was only one study related to each of them. In both areas, the only technology that occurred was the R language. In the "Armed conflicts solution" area, two terms related to techniques occurred: Document-Term Matrix and SMOG Index Calculation. The SMOG is an index related to the fact that adults use words in writing in a richer and more complex way than children. There are two other terms in the "Violence against woman analysis" area: Sentiment Analysis and Term Frequency. Figure 2 is a word cloud showing the most frequent word associated with the term related to technologies and techniques from the selected literature, separated by uni- grams.
In Figure 2, the central and most frequent word is “frequency” both associated, for instance, to “term frequency/” and “term frequency-inverse document frequency”, very recurrent statistical measures for words counting in text mining. In a second level, term as “support”, “vector” and “machines”, “naïve”, “bayes”, related baseline machine learning techniques appear, as well as “python”, the most recurrent programming language in the selected literature. The following section will address the opportunities and challenges for text mining in public security found in the selected literature.
For each of the areas where there were indications of future work, in the list of 92 articles that contain this type of indication, extracted from the more extensive set of selected literature, a synthesis of these indications will be presented to identify opportunities and challenges for the outline a research agenda.
It should be noted that not all 19 identified areas have works with mention of future directions to be presented in the construction of this part of the text; thus, following, the seventeen areas with works containing the desired information are presented.
The cybersecurity application contained the largest number of further development and research proposals, with twelve directions indicated in 2018, eight in 2019, and eight in 2020.
Elkhawas and Abdelbaki (2018) presented an approach using trigrams and portable executable file attributes as features for malware detection, suggesting the automation of the mining process and using other techniques than those previously used. They also commented on using support vector machines with larger datasets to improve accuracy by including more features, performing more experiments, and trying to group malware in families.
Hadad et al. (2018) also developed research dedicated to malware detection, suggesting using more features in the malware detection process through user-generated content instead of libraries or sets of codes. Ariffin et al. (2018) built a ransomware background knowledge base and indicated the need to extract more features using texts to identify ransomware families.
Silomon and Roeling (2018) mined people's opinions about the concept of “Software as a Weapon” by linking traditional aspects of weapons to understand the differences between software and malware used from an international security perspective. They suggested reducing the questionnaire to collect the opinions by selecting the most informative questions according to the highest factor loading for the related components.
Chung et al. (2018) developed an approach to identify social media resources correlated to abnormal stock returns from vulnerable companies targeted by cognitive hackers. They indicated that the experimental results of the research would be open for researchers interested in applying their approach to obtain additional evidence for its effectiveness.
Dong et al. (2018) proposed a framework for discovering new cyber threats in darknet marketplaces with new research ideas on how to extract information from short texts (also considering foreign languages) in the dark web, obtaining more features for classification, and applying natural language processing to increase the performance of the framework.
Concepción-Sánchez et al. (2018) proposed a text mining and fuzzy logic system to detect compromised user accounts. They suggested incorporating other methodologies to improve the system's decision-making and indicated the development of a mobile application using a theft detection system like the one they proposed.
Husari et al. (2018) developed an approach to automate the extraction of low-level cyber threat actions from publicly available intelligence sources to enable timely defense decision-making. Their indications for future works were related to the extension of the approach for viewing threat action as a verb-object representation to other syntactic blocks and proposed a new way to automatically parse all types of threat action expressions by extracting them to provide vital information for more analysis.
Ruano-Ordás et al. (2018) developed an empirical study about concept drift to discover its origin, types, and undesired effects in the context of e-mail classification. Their future research ideas were related to measuring the impact of the proposed methodology in various scenarios, developing new methodologies to estimate the performance of classification systems without changing the underlying concept drift, and designing new classification systems to detect specific types of concept drifts in real-time.
Zainal et al. (2018) produced a tool to aid users in distinguishing potentially severe spams by measuring the risk in the content. They identified further directions by developing an automated environment for new experiments with a prototyping dendritic cell algorithm and its deterministic version. They also suggested using a larger-sized corpus, checking its consistency and reliability, and applying new simulations to validate the severity concentration assessment in other spam forms.
Sonowal and Kuppusamy (2018) presented an anti-phishing model, entitled Smishing Detection based on Correlation Algorithm, and indicated the use of a new feature selection algorithm to obtain more varied features. They also suggested exploring deep learning techniques and enhancing the prototype model's user interface as future directions.
Samtani et al. (2018) presented an approach to identify Supervisory Control and Data Acquisition (SCADA) devices through a search engine to find computers connected to the Internet and then assess the vulnerabilities of the devices with a state-of-the-art tool. They suggested the new work may be interesting for identifying specific device owners and locations, categorizing the devices in a fine granulation to understand vulnerabilities that affect some subsets, and employing assessments at regular intervals to know how SCADA vulnerabilities evolve.
Balim and Gunal (2019) proposed a machine learning-based model to detect smishing messages in short message services. They indicated that for future studies, one way forward is to apply smishing message analysis in other languages, using different features and classification algorithms.
In their study, de Boer et al. (2019) proposed the Horizon Scanner tool, based on crawling and scraping relevant text databases on potential threats and trends in cybersecurity to speed up forecasting. The authors indicated that future interactions with their tool would emphasize human-centered aspects, such as workflow support and greater explanation and controllability of the analyses.
Gravanis et al. (2019) proposed a model for fake news detection using content-based features and Machine Learning (ML) algorithm. As advances in their original proposal, they highlighted the use of multiple metadata about the source and author of the news, along with information dissemination capabilities on social media and the use of deep learning methods with larger datasets to improve detection of false news.
Kakavand et al. (2019) proposed the anomaly detection system called Online Adaptive Deep-Packet Inspector to classify web service message attacks. As a perspective for further developments on their proposal, they indicated the possibility of analyzing larger volumes of information to ensure an effective scaling of the detections for which the system was developed.
Mohasseb et al. (2019) investigated how the data from multiple companies representing different incidents can improve classification accuracy by aiding the classifiers to identify different types of incidents. The use of other datasets and machine learning techniques and the investigation of class imbalance to improve the classification accuracy were directions identified for future research.
Roopa and Induja (2019) proposed a framework based on text mining to avoid the risk of opening suspicious e-mails and suggested further work in the customization of this framework by improving the classification of sentiments towards the online content and incorporating library files for selective predictions.
Sudha and Rupa (2019) developed a framework to classify and match the various cybercrime incidents using the Naïve Bayes classifier. They comment that advances in the system can be implemented, ensuring that preventive measures are also suggested based on the results.
Palad et al. (2019) seek to determine whether predictive text mining analytics can be used effectively to identify and classify online scam data to gain insights and help uncover patterns in a cybercrime dataset that assists in criminal investigations in the Philippines. They highlight that developing or obtaining more inclusive or relatively large cybercrime datasets in future studies is necessary to significantly improve relevance of the results.
Alagheband et al. (2020) analyzed cybersecurity trends to propose a conceptual framework for identifying cybersecurity topics of social interest and emerging topics that need to be addressed by researchers in the field. Three considerations can be pointed out about future studies based on the authors' comments: (i) apply gap analysis of cybersecurity trends between newspaper corpora and cybersecurity whistle-blowers to reveal some noteworthy points; (ii) explore the correlation between cybersecurity-based standards and patents with either academic papers or the whistle-blowers’ reports to yield new insights to be studied, for instance, using causality analysis; and (iii) use the proposed framework for other applications or even some specific and targeted sections of cybersecurity.
Al-Ramahi et al. (2020) extracted topics of interest from hackers’ websites to use them as security controls and systems inputs. They suggest integrating these topics of interest as a new category of commitment indicators for application security controls and systems for future studies.
Battaglia et al. (2020) proposed a way to evaluate the harmfulness of any form of content by defining a new data mining task called “content sensitivity analysis”. They define two directions for further studies: (i) investigate more complex techniques borrowed from machine learning, computational linguistics, and semantic analysis; and (ii) build massive and reliable annotated corpora to ensure that the performance of any content sensitivity analysis tool is sufficient, no matter how complex the learning model.
Calderon et al. (2020) compared the performance of decision tree classification algorithms using a large dataset to assess whether such algorithms can be used effectively in data mining efforts to positively impact or contribute to criminal investigations. They highlight two possibilities for future studies: (i) compare the results obtained from the classifiers with other decision tree classifiers implemented in WEKA and investigate what causes the difference in the performance of such algorithms; and (ii) perform weight allocation, subsequently applying rank approaches to ranking classifiers.
Ma et al. (2020) presented a data-driven approach, based on text-mining methodologies, for classifying transient events and identifying fake events caused by false data attacks in power systems. These authors separated three directions for the development of new studies: (i) include a more diversified set of power system events for classification purposes, such as the switching of synchronous motors; (ii) investigate other types of data spoofing strategies to provide more information on applications of the proposed approach; (iii) use other useful information recorded by phasor measurement units to improve the accuracy and robustness of the proposed approach.
Palad et al. (2020) significantly improved their previous study (Palad et al., 2019) based on the identified research problems: relative small datasets and different classification methods. They suggested comparing the results obtained from these decision tree algorithms by applying appropriate weight allocation and subsequent ranking approaches to evaluate those classifiers. They also commented that the classification of cybercrime data could be conducted using other available data mining tools or techniques.
Samtani et al. (2020) developed a cyber threat intelligent detection framework called “Diachronic Graph Embedding Framework” to explore online hacker forums to identify emerging threats in popularity and tool functionality. The authors determine that the framework can be employed in other related areas, such as improved memory forensics and malware evolution on datasets extracted from VirusTotal (an online URL analysis service to identify malicious content).
Pires and Georgieva (2020) developed an intelligent tool for phishing detection based on machine learning that integrates only local information and does not rely on blacklists or other external sources. The authors commented that implementing the proposed tool in commercial environments would be favored if embedded into a platform for online message labeling. They also pointed out that periodic retraining with recently accumulated labeled data over a limited time would guarantee a smooth adaptation to new attack trends.
The “General crime detection/prediction” term was the second set of applications that included further development indications, with six in 2018, five in 2019, and five in 2020. The research by Aghababaei and Makrehchi (2018) (i) verified the contribution of content extracted from Twitter in a crime prediction model, (ii) identified an efficient time forecast model that captures the most relevant resources, such as time topics for forecasting, and (iii) explored the temporal effects of the content of crime directions to determine the lag between the predictive features and the crime trends. They proposed for future research working on a sampling approach to avoid the loss of user activities and collect data from historically active users to allow the use of text semantic analysis to better understand the relationship between resources. Additional analysis incorporating other socioeconomic and geographical information correlated with information on criminal activities was also suggested.
AL-Saif and Al-Dossari (2018) intended to detect crimes, identify their nature using different classification techniques, and evaluate their speed and accuracy performance. They suggested including a spatial and temporal analysis to determine when and where crime has spread earlier to help predict how it is likely to spread in the future.
Percy et al. (2018) identified regions for which data had internal similarities and could be combined for creating a reliable crime prediction model. They suggested incorporating a time-series into the developed model by using, for instance, Long Short-Term Memory modeling of sequential data.
Po and Rollo (2018) analyzed and mapped thefts through online newspapers using text mining techniques for an Italian city. The following were recommended for future developments: (i) seek collaboration with law enforcement agencies to deal with real-time crime data, (ii) perform analysis and integration of crime news from other local newspapers, (iii) remove news duplicates, (iv) represent more types of crimes, (v) apply topic detection, (vi) apply advanced crimes analysis, and (vii) transform the stored information in linked open data.
Ristea et al. (2018) explored the spatial relationship between crime events and nearby Twitter activity around a football stadium by estimating the possible influence of tweets for explaining the crimes’ occurrences in the neighborhood on match days. The suggested directions for further research were (i) perform seasonal analysis of crime patterns by increasing the database for performing comparisons, (ii) expand the study space to include areas that may also experience changes in crime according to different conditions caused by large-scale events, and (iii) model variability in crime volumes on weekdays compared to weekends as dependent variables.
Tran and Tran (2018) proposed techniques for aspect extraction and sentiment analysis in aspect-based opinion mining problems with applications in criminal activities analysis. They indicated further research to improve proposed techniques performances, solving the problem of determining the strength of opinions, analyzing opinions expressed with adverbs, verbs, and nouns, and developing more research and experiments in political and security domains.
Mine et al. (2019) investigated if crime messages sent by e-mail can be further explored as a valid source for analyzing the criminal characteristics of a region. They proposed employing other machine learning techniques, particularly Gradient Boost Decision Trees and Deep Neural Networks, to develop a method for automatically extracting essential features from the crime reports. They also suggested developing methods for analyzing and tracking temporal and spatial changes in crime and predicting local crime.
Das and Das (2019) proposed a graph-based clustering technique for discovering labels of crime reports based on extracted paraphrases from large untagged crime corpora. They determined the need for developing an automatic system for labeling the crime reports based on extracted paraphrases.
Malim et al. (2019) studied annotated sentiments in a list of Malaysian Tweets possibly subject to crimes or illicit messages from the stance of the psychotic trait to recognize criminal activities using machine learning. They highlighted as a possible evolution of their study “the use of more data to predict criminality texts by incorporating artificial intelligence and deep learning concepts”.
Nedeljkovic et al. (2019) developed a study about the similarity measure that provides the most precise results about the crime domain in a question-answering system. They specified the need to develop a new system that will not be necessary to involve an expert.
Savaş and Topaloğlu (2019) examined the wisdom of crowds on crime issues from social media to illustrate the relationship between social whispers and the current crime situation in Turkey. Changes in keywords, filters, and target groups applied to the same analysis in other fields were indicated for future research.
The study by Alatrista-Salas et al. (2020) intended to determine what types of crimes were perpetrated based on the news. They defined four points for further studies: (i) extend the applied methodology to an online platform that can process and analyze streaming documents; (ii) answer the questions about who commits a crime and where to enrich the methodology applied to build a comprehensive approach; (iii) extend the methodology applied to other languages and criminal texts; and (iv) improve points such as time, memory efficiency and the ability to build a classifier capable of detecting more than one crime in a given news article.
Birks et al. (2020) sought to identify specific crime groups from unstructured free texts containing modus operandi data within a single administrative crime classification. The authors defined four directions for future research based on their study: (i) to assess the applicability of the latent Dirichlet allocation for free text associated with other crimes; (ii) the use of other topic modeling techniques besides the latent Dirichlet allocation, allowing the incorporation of additional variables in the model; (iii) compare and contrast the space- time structure of different types of assault modus operandi as identified through the model; and (iv) use the probability of allocation of topics to documents to identify new or emerging modus operandi of crimes from documents that are not well categorized by latent Dirichlet allocation when trained against an existing model, supporting the development of early warning systems that can identify emerging criminal behavior.
Mukherjee and Sarkar (2020) proposed a system that automatically extracts crime locations from huge newspaper collections to get the picture of high crime-prone locations in a given locality. They define two directions for future studies based on the proposed system: (i) use more training data for tagging crime information with Conditional Random Fields, and (ii) apply deep learning to improve each system module.
Lal et al. (2020) analyzed Twitter data to identify tweets about crimes that need police attention, proposing an approach to doing so. They define five directions for further studies on the topic they worked on: (i) using more classifiers to test the effectiveness of the proposed approach; (ii) adding location information to the crime tweet to help police identify the crime location; (iii) apply a set learning-based approach to crime tweet classification; (iv) apply natural language processing techniques such as grammar class markup to improve resource extraction; and (v) carry out a comparative analysis of the approach they used with the other approaches.
Saldana et al. (2020) presented a methodology for analyzing criminal facts in online newspapers, identifying the different communes where the greatest number of criminal events occurred. They suggested the use of a more significant number of sources such as social networks, the breakdown of events by limited geographic areas (streets or sectors of a given commune), and the incorporation of techniques such as sentiment analysis to study in more detail at levels of violence associated with specific events.
Works on “Fraud detection” applications with comments about further research appeared in two papers in 2018, three in 2019, three in 2020, and one in 2021. Bhardwaj and Gupta (2018) proposed a text mining framework for detecting financial statement fraud by identifying and analyzing the linguistic data available in financial reports. They suggested future work implementing the proposed framework using a dataset of fraudulent and non- fraudulent financial statements and text mining tools.
Lee et al. (2018) presented a new forward and backward analysis methodology implemented in an Information Extraction prototype system. The following future research directions were derived based on the limitations of the developed work indicated by the authors: (i) work on a keyword extraction template for other financial crimes on financial discussion boards, (ii) use other data artifacts, such as “broker ratings” and “director deals,” for the forward and backward analysis, and (iii) program the prototype system to obtain comments through HTML files by crawling comment data from financial discussion boards.
Dastjerdi et al. (2019) applied text mining to detect high fraud risks in companies to compare their precision. Their set of techniques included: F-Limer and Hausman tests to determine the type of pooled data; the modified Wald test for heteroscedasticity in the fixed- effect regression model; the Wooldridge test for autocorrelation of residuals in the panel data; Convex Optimization, Minimum Absolute Reduction, and selection operator regression techniques to perform fraud risk detection. Their future research indications included (i) the use of other methods, such as neural networks, genetic algorithms, decision trees, Bayes analysis, and fuzzy analysis, for comparison purposes, (ii) the use of other text, such as an auditor report, (iii) increase the periods for fraud detection on the analysis, and (iv) develop a new analysis for different languages and in other countries.
Rabuzin and Modrušan (2019) compared prediction models using text-mining and machine-learning techniques to detect suspicious tenders in public procurements and to apply these techniques to develop an approach to detect suspicious one-bid tenders. They comment that it is necessary to include additional indicators to increase model accuracy and apply neural networks, deep learning, and other machine learning algorithms for better results.
Sahu et al. (2019) proposed an architecture for credit card fraudulent transaction detection using machine learning. The authors defined that new studies can be developed on the attribute name not provided in the applied dataset. They also suggest that different classifications can be performed using Greedy Search Optimization and genetic algorithms to get better results. Collecting a more extensive dataset to improve predictions is another direction the authors set for further studies.
Angenent et al. (2020) applied machine learning to perform explainable business sector predictions from financial statements with fraud detection applications. The authors highlighted as a perspective for future work “using other classification algorithms, optimized hyperparameters, and different data sources, such as written annual reports (for text mining)”.
Kabwe and Phiri (2020) presented a metrics model based on distance metrics to quantify the credential identity attributes used in online services and activities to detect identity theft. They define as a continuation of their research the implementation of the results obtained for constructing a multimodal solution, consolidating previous work in this area, arriving at a single and robust solution capable of recognizing how much threat must be eliminated in services and online activities.
Monish and Pandey (2020) applied a comparative analysis of data mining models for fraud detection to predict fraudulent firms. They provided three directions for future work: (i) compare advanced deep learning algorithms for text classification, such as recurrent neural networks; (ii) explore new advanced ensemble techniques to make further comparisons of models; and (iii) explore data mining techniques other than text, for example, analyzing multimedia data such as audio, video or images.
Siering et al. (2021) developed an artifact that can act as a robust classifier by providing an assessment of whether a given document is suspected of being fraudulent applying it to the stock market. The authors indicated several directions that could be taken in future studies and developments: (i) the inclusion of the proposed fraud detection classifiers in a fraud detection system to improve the "information-based market manipulation detection capabilities" of companies and market surveillance authorities; (ii) the use of classifiers to complement established fraud detection systems covering other manipulation scenarios; (iii) the inclusion of classifiers in browser toolbars, which already generate warnings for phishing sites; (iv) the use of design principles and design features to improve the robustness of the classifier by applying it to other fields or languages; and (v) to investigate the robustness of text-based classifiers in the social commerce context.
Terrorism detection applications presented eight works with future research recommendations, with five in 2018, one in 2019, and two in 2020. Al-Khalisy and Jehlol (2018) worked on a method for detecting tweets with terrorist ideas and identifying the location of people who own these posts and proposed applying their method to other fields.
Alguliyev et al. (2018) proposed a method for detecting terrorism-related activities in e-government environments and proposed further experiments based on the method compared to other approaches. Mansour (2018) examined what eastern and western people think about ISIS and investigated if there is a significant difference between the proportion of negative and positive words within users' tweets from both regions. They suggested repeating the study to include more countries to collect more tweets for generalizing the results and collecting multilingual tweets for analysis in different languages.
Öztürk and Ayvaz (2018) investigated the public opinions and sentiments towards the Syrian refugee crisis and suggested including more languages for further study. Zahra et al. (2018) presented an approach applying machine learning algorithms to identify extremism-related content and users. They proposed, for future studies, the use of demographic information, user activity feeds, and links between users to detect the location of extremists.
Petrovskiy and Chikunov (2019) proposed an approach for detecting radical users in social networks by analyzing their relationships and features as vertices on a social graph without using textual content they generate. Their recommendations for further analysis included (i) applying an extension of the label propagation approach by imitating topics spreading between users based on their relationships, (ii) including this information for radical members of social network detection to improve quality, and (iii) predicting the probability of occurrence of communication between users in time to prevent extremist activities.
Castillo-Zúñiga et al. (2020) proposed a methodology to obtain added value from datasets extracted from hundreds of downloaded web pages and developed a software architecture to test this methodology, applying it to cyberterrorism vocabulary detection. The authors pointed out the need to carry out studies related to messages that include terrorist content on Facebook and Twitter, using sentiment analysis and opinion mining techniques to extract people's comments and classify the emotional tone.
Miranda et al. (2020) studied radicalism intention using content detection. They pointed out a direction for future studies based on sentiment analysis techniques to improve content detection and classification performances.
Two works included future research recommendations in Digital/Cyber forensics applications: one from 2018 and the other from 2019. Giacalone et al. (2018) opened a debate on the study and use of statistical and computational methods for web data on new forensic topics, proposing a system for predictable jurisprudence using automatic sentence analysis. The authors also proposed, for future research, dealing within a Big Data context by considering the map/reduce approach with a real estimation of the evolution based on the solution they presented to analyze administrative judgments.
Henseler and Hyde (2019) proposed using a graph database and query language to assist in answering key digital forensic investigation questions. The authors defined three new study lines based on their work: (i) study how forensic investigators can interact with the graph generated by their approach and how to extend the graph with other data sources; (ii) study how events on a timeline can be added to the graph, how non-digital evidence information can be included, and how to improve the performance of existing entity extraction techniques in unstructured email and documents; and (iii) study whether new machine learning techniques, such as graph neural networks, can be used to learn from investigators which link and event patterns are interesting from the investigator's point of view.
Nine works with future development indications were found in the cyberbullying detection application area: two in 2018, one in 2019, four in 2020, and two in 2021. Alakrot et al. (2018) built an offensive language-based database to detect antisocial online behavior. They presented an exploration of more pre-processing techniques and machine learning algorithms to create better offensive content detection models in Arabic online communication as continuity for their research.
Ventirozos et al. (2018) presented a new approach using the sentiment analysis at the message level but considering the entire communication thread as the context of the aggressive behavior. They proposed investigating the representation of sentiments as word embeddings learned through deep neural networks as a future development for their research.
Andleeb et al. (2019) proposed a text mining framework to detect bullying text proactively. They commented about using specific adaptations to make the framework data- independent and to use it for any other dataset for future works. They also commented about adding more bullying words in the bullying words list to make the study suitable for real- world problems. As the last direction, they defined applying sarcasm detection to further improve the framework's performance.
Adikara et al. (2020) studied cyberbullying detection on Instagram comments divided into two classes: cyberbullying and non-cyberbullying comments. For future works, the authors defined the exploration of methods such as support vector machines or neural networks to verify their detection rates, demonstrating that these methods are suitable for the application in cyberbullying detection.
Ishara Amali and Jayalal (2020) introduced an automatic approach to detect Sinhala language social media comments to insult a person. For further research, they pointed out: (i) expanding the data corpus to include Sinhala language comments that are also written using English characters; (ii) improving the applied model to obtain high accuracy with increasing recall value with a larger data corpus; (iii) the expansion of the Sinhala swearword list, with the help of the participants in the labeling system and with the knowledge of experts; and (iv) the automation of the manual labeling process to make the process more efficient.
Slamet et al. (2020) analyzed text documents on social networks and then classified them into two classes: one with indications of bullying and the other clean concerning these indications. They proposed two advances over what they had already developed: (i) add more documents to increase accuracy; and (ii) use the supervision of a linguist and manually check the dataset that will be used in the training and testing process so that the documents to be processed are entirely free from noise and other errors.
Wang et al. (2020) proposed a multimodal detection framework using multimodal information in social networks to deal with cyberbullying. For future developments, they defined the use of multimodal information fusion in cyberbullying detection, considering modal data associations in social networks, supporting the modeling of new types of cyberbullying behavior.
Bozyiğit et al. (2021) tested the classification of online bullying content by using social media variables with classical text mining approaches. As proposals for future work, they highlight: (i) create datasets belonging to different countries/regions that use the same language to compare the effects of social media demographically; and (ii) implement a fuzzy rules-based system for current approaches using predictions based on social media.
Choi et al. (2021) proposed a practical method of identifying social network users who make high rates of insulting comments. For research purposes, the authors defined their method as a basis for further studies since no methodologies are dedicated to identifying key cyberbullies. The authors consider using the proposed method to classify benevolent comments for practical purposes. They also pointed out that identifying and ranking key cyberbullies can help online platform operators mitigate cyberbullying.
Among the works related to supporting law enforcement agencies, four presented directions for further research: both 2019 and 2020 had two works. Basilio et al. (2019) developed a methodology for knowledge discovery in emergency response service databases based on police occurrence reports to support law enforcement agencies planning to investigate and combat criminal activities. They appointed interactions with multi-criteria methods to support decision-makers choosing actions to identify illegal demands as activities for future research.
Behmer et al. (2019) designed a systematic approach for the processing and extracting formalized semantic concepts to assist criminal investigations and suggested using instantiated information, such as temporal sequences, to support semantic reasoning about the occurrences of events and assist in criminal identification.
Basilio et al. (2020) developed a method for knowledge discovery in emergency response databases based on police incident reports. From their research, they were able to make the following indications about future studies and developments: (i) apply the optimization of material and human resources in the application of policing strategies; (ii) improve the modeling using other multicriteria decision aid methods, such as PROMETHEE V; and (iii) and carry out research expansions in other countries to consolidate results on the impact matrix of policing strategies.
Hou et al. (2020) proposed a “Bidirectional Encoder Representation from Transformers” based on the Chinese language relation extraction algorithm for public security, which can effectively mine security information. They proposed further exploring the application of deep learning in relational extraction and developing the model for public security and the Chinese language structural analysis.
For the sex-related crime detection applications, only one work suggested further research. Hultgren et al. (2018) proposed an information system approach to identify sex trafficking victims based on analyzing online ads and specified the following directions to improve the system: (i) examine male victims to see if the indicators and keywords are different compared to female victims, (ii) investigate technologies to create an automated knowledge management system on the topic, (iii) develop an automated data extraction process, (iv) use data from online services for adults to develop studies considering the sex industry, and (v) determine the meaning of emojis in texts to assess if they can be used to detect victims of sex trafficking.
The support for judiciary applications counted three works with future research directions. Iftikhar et al. (2019) developed a legal mining system based on machine learning algorithms to recognize named entities on judgment texts. They indicated for directions of further work (i) the inclusion of other types of judgments to be tagged and used in training and testing of algorithms, (ii) the preparation of a comprehensive dataset, containing a variety of court judgments, (iii) the application of various deep learning algorithms for named entity recognition and preparation of specialized pre-trained word embedding for legal text on legal text, and (iv) providing a variety of applications on extracted named entities.
Pina-Sánchez et al. (2019a) reported the results of an analysis on a new sentencing database to explore if offenders with common Muslim names attract a different sentence and if any notable differences can be attributed to discriminatory sentencing practices. The authors highlighted the following elements to be considered in new research: (i) convert sentences to a reduced and censored form for use by specialists in other areas who are interested in performing analyses on these sentences, (ii) link the Sentencing Council data to the Ministry data by capturing the ethnic background of the defendant, (iii) conduct multivariate analyses to determine if there is evidence of ethnic discrimination in sentencing, and (iv) include all decisions taken before the final sentence for analysis.
Xia et al. (2019) evaluated the effect of judge gender on judicial decision-making in China. They indicated the need for further study on the interaction between gender roles, legal and extra-legal factors in judicial processes.
The work by Cichosz (2018) was the one identified with new research directions in drug-related crime detection applications. The authors developed a study applying classification algorithms to categorize forum posts as drug-related. As advancements to their work, they suggested (i) to include more selection algorithms for text mining purposes by comparing their performances, (ii) to explore enhancements for the process of deriving bags of words and the text representation referred on the article, (iii) to incorporate additional non- text attributes in the representation of forum posts by trying to improve the quality of the classification, and (iv) use manually annotated class labels to represent the discussion topics.
Only one work with directions for future research occurred for Espionage Detection, published in 2020. Glancy et al. (2020) analyzed the association between malicious insiders’ characteristics and the different types of attacks on organizations. The authors commented that they would attempt to enlarge the sample size by adding new cases reported by the news media in future research. They also intend to focus more on the mechanism and overarching theories to explain the behavioral patterns of malicious insiders.
Crime victim support applications presented indications for new research development in one paper from 2018, one from 2019, and two from 2020. Karystianis et al. (2018) examined if automatic text mining of domestic violence police event narratives is feasible for identifying mentions of mental health disorders at the narratives of people involved by employing a knowledge-driven approach. They recommended for future research: (i) examine the authenticity of informal mentions of mental health disorders through formal diagnoses in administrative data collections, (ii) expand the set of information extracted from police narratives to assess the characteristics of people who committed violence and victims for risk groups, (iii) create predictive models to investigate if recurring domestic violence events are predictable for groups at risk by informing preventive strategies.
In a second study, Karystianis et al. (2019) took a similar approach as the previous article by investigating if the application of text mining can automatically extract abuse types and sustained victim injuries from a corpus of domestic violence events. Their recommendations for future research included: (i) use information from a corpus of domestic violence in combination with the collection of administrative data on mental illness to further examine the links between mental illness and domestic violence, exploring the relationship of types of abuse with gender and victim injuries, (ii) perform a new analysis by combining demographic variables with the results previously achieved, (iii) combine victim injuries extracted from clinical data resulting from contacts with health services to assist in identifying victim abuse and implementing intervention strategies, (iv) apply modeling to investigate if people with characteristics of interest can predict the severity of the abuse by assessing if specific victim phenotypes are prone to specific abuse.
In a third study, Karystianis et al. (2020) presented the prevalence of extracted mental illness mentions for persons of interest and victims in police-recorded domestic violence events, following a line of work that continues the previous two. The authors commented that information drawn from a police domestic violence dataset suggests that there may be more detailed information on mental illness trends in victims and persons of interest. This approach can provide the basis for examining the agreement of extracted mentions of mental illnesses with the official diagnosis of health records and surveys that aim to assess victims and person of interest characteristics in police records. There is also the idea that the information extracted can be used to design predictive models about the risk of further victimization, informing prevention strategies that can be implemented in the early stages of police involvement in a domestic violence event.
Lyu et al. (2020) applied sentiment analysis over textual data from Weibo social media to explore people's attitudes towards child abuse incidents, the reasons behind them, and how people's emotions will become the potential driving force for improving child protection policies in China. The authors consider applying machine learning in sentiment analysis as an ideal way to improve the accuracy of this type of analysis in textual data, indicating this possibility for future studies.
Software piracy detection applications appeared in two works: one from 2018 and another from 2019. Kim et al. (2018) proposed a software classification scheme for an efficient software filtering system, applying it to detect pirate software. They recommended devising adaptive techniques by applying static and dynamic characteristics to study the trade-off between analysis speed and detection of overshadowed programs. Sarwar et al. (2019) proposed a new software birthmarking approach based on hybrid text and graph mining techniques to support pirate software detection. Their recommendation for future work was to test a hybrid approach to software theft detection using graph-based birthmarks and software watermarks.
Here, there is a combination of two of the identified areas of text mining application in public safety, where there was only one work specifically in 2020. Al-Nabki et al. (2020) presented an end-to-end neural network architecture to recognize emerging and infrequent named entities in noisy user-generated text, supporting detecting suspicious activities associated with weapons and drug selling in Darknet. To continue their research, the authors considered representing the context of the input token by evaluating its Local Distance Neighbor vector using Bi-directional Long Short-Term Memory to see how this improves the method's performance.
They also pointed out using other space-embedding representations such as FastText or StarSpace to represent the training entities so that the cosine similarity can be measured between the input token and the training entities instead of the training tokens. As the last point, they commented on incorporating graphical resources extracted from images published in Tor domains, which would hopefully increase performance
Applications in armed conflict solutions contain one work by Correa et al. (2018), who proposed a methodological approach to show how to linguistically analyze peace agreements as acceptable political products based on the difficulty of the text. As a direction for future work, they commented on the need for analyzing peace agreements of other non- Spanish-speaking cultures and failed peace accords by adapting the script developed for the research they applied.
Weapons’ trafficking detection contained one work by Saini and Bansal (2019). The authors proposed a novel approach to identify the procurements of modern weapons over the dark web forums by terrorists. They suggested enhancing the illegal weapon procurement model to support different languages used by violent extremists in dark web forums and apply social network analysis. Another suggestion was to use topic modeling to discover more hidden patterns in the dark web and detect more illegal activities.
Civil unrest detection is the final public security-related application area for text mining containing future work directions. Wei et al. (2020) examined the changes in the behavior of Twitter users regarding prejudice against immigrants following recent protests in the United States on topics related to immigration. The directions for further study were: (i) improve prediction of change at the user level with better-annotated data; and (ii) study a broader population in different countries and study the long-term effect of protests on online prejudice.
It is important to comment on the ethical question in using text mining in public security to close the discussion. In several cases of application of text mining techniques, issues regarding ethics in using sensitive and personal data emerge, even though these data are necessary for some action aimed at people’s security. Some articles made comments about the ethical use of data about people, victims of abuse, or crimes in the selected literature.
Hultgren et al. (2018) highlighted the problem of using data on victims of sexual exploitation. This was one of the main limitations of his research for accessing information since, for reasons related to research ethics, it was not possible to make direct contact with people in this condition. This fact alone demonstrates the delicacy of the matter. Neither the victims wish to expose themselves for their safety, nor do law enforcement authorities publish detailed textual records to avoid exposing these people, whether scientific research.
Karystianis et al. (2018), Karystianis et al. (2019), and Karystianis et al. (2020) accessed domestic violence case data to develop their studies. However, they commented about the ethical issue in using the data source (a police narratives base). A strict security protocol was applied, ensuring that the text mining of the cases’ narratives could only be carried out in loco, at the headquarters of the police department in the region where the study was carried out, and only de-identified outputs could be extracted to be applied on their research. In summary, the use of text mining tools could be considered ethical if it is oriented towards maintaining social welfare, avoiding the exposure of people mentioned in texts, and following the information security regulations required by public security authorities.
The detail presented in this article brings all the selected literature, with the separations related to each of the items targeted by the research: (i) main application areas, (ii) techniques and technologies employed, and (iii) opportunities and challenges according to the most recent literature (from 2018 to 2021), looking at the directions or proposals for future research. While in (i) and (ii), the whole selected literature with 194 works was explored, in (iii), a subset containing 92 works was extracted. A publicly available repository was created in GitHub (see the footnote of Section 3.4 in the present text) and a spreadsheet with all information extracted from the works selected in the systematic review process.
Nineteen application areas related to public security were identified. The related literature was presented among Tables 1 and 10, with the last two tables grouping two or more application areas and subsequent text, presenting areas with smaller amounts of literature (one or two works only). After presenting the application areas, the most recurrent techniques and technologies applied were presented according to each identified area, with data being complemented with a series of tables in Appendix A.
Detailing about future research directions of the 92 most recent works is presented, separating them according to the seventeen application areas in which they were detected, describing these directions in a summary paragraph. A final comment was made regarding the ethical question in using text mining in public security, demonstrating the importance of ensuring that sensitive data, particularly about people, are kept confidential to avoid compromising their physical and social integrity, demonstrating some works that illustrate restrictions in this regard.