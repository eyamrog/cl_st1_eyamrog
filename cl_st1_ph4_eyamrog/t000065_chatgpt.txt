Compiling a corpus poses a significant challenge for researchers, yet it remains a popular pursuit. Despite the availability of some learner corpora like the International Corpus of Learner English, accessing a diverse range of text registers from English learners at various proficiency levels within the Brazilian university setting is limited. This paper aims to address this gap by introducing a learner corpus, essential for our research and teaching environment, emphasizing the benefits of such a corpus in understanding learner needs and informing pedagogical decisions with reliable data. By outlining the rationale behind the corpus compilation process, this article elucidates the strategic decisions taken to ensure equitable comparisons. Through a comparative analysis with previous studies, the importance of a meticulously constructed corpus is underscored. Findings highlight the necessity of discipline-specific tasks to enhance writing skills and the cultivation of authorship abilities in English for Academic Purposes classes to support academic achievement.
When linguists embark on selecting their research questions and determining the investigative approach, a multitude of decisions must be carefully considered. Undoubtedly, the methodology employed must align seamlessly with the objectives of the study. Opting for a corpus linguistics methodological framework could prove to be the most suitable option when exploring inquiries pertaining to the diverse ways in which language is utilized across various contexts, as emphasized by Crawford and Csomay.
Researchers across various linguistic disciplines share a common objective of comprehending variation and contextual nuances. In the realm of corpus linguistics, this goal is achieved through the examination of extensive textual data generated under comparable conditions. As highlighted by Crawford and Csomay (2016, p.5), corpus linguistics delves into the study of language variation and usage by analyzing substantial volumes of text.
This empirical approach enables the generalization of results, as a well-designed corpus can effectively represent a register, defined as "a variety associated with a particular situation of use (including particular communicative purposes)" (Biber & Conrad, 2009, p. 6). The researcher must consider the situational characteristics of a register, including the participants, their relationships, the communication channel, and the production circumstances (Biber & Conrad, 2009). Once clear research questions and the characteristics of the register(s) of interest have been established, the next step is to select the appropriate corpus. Should a readily available corpus suffice, or would a custom compilation be necessary?
In the realm of learner language research, access to corpora is limited, with examples including the International Corpus of Learner English (ICLE), the Louvain International Database of Spoken English Interlanguage (LINDSEI), Louvain Corpus of Native English Essays (LOCNESS), the Michigan Corpus of Upper-Level Student Papers (MICUSP), and the British Academic Written English corpus of English texts (BAWE). Each of these corpora serves a specific purpose, with ICLE and LINDSEI focusing on English learners' interlanguage, MICUSP and BAWE on high-grade written papers of various genres, and LOCNESS on essays by American and British university students. Despite differing compilation purposes, these corpora share situational characteristics, with participants being higher education students who write or speak in assessed or non-assessed contexts, with or without time constraints. While production circumstances may vary, the authors are typically novice or apprentice writers. The primary distinction lies in the participants' diverse first language backgrounds. Considering our research context at a Brazilian university, limitations arise when relying solely on these existing corpora. Despite their size and the inclusion of a subcorpus of essays by Brazilian students in ICLE (Br-ICLE), they prove insufficient for our needs, particularly in exploring linguistic variation across genres, academic levels, disciplines, and proficiency levels comprehensively. To address these gaps, we aim to create a new corpus, offering a CQPweb framework for researchers to access, featuring tools like keyword search, collocate lists with various association measures, and visualization of occurrence dispersion.
To the best of our knowledge, there was no comprehensive learner corpus of Brazilian university learners’ English written texts compiled in the classroom context and available for the studies our research group was aiming at. Therefore, in 2013, as Section 3 lays out comprehensively, a Brazilian learner academic English corpus was designed (CorIFA9). Our efforts were motivated primarily by our desire to enhance learners’ use of academic English. Corpus analysis enables the study of a specific group, and the compilation of the corpus appeared to be a significant challenge worth pursuing, as it would serve as the foundation for creating appropriate materials and new courses. Consequently, the aim of this paper is to introduce the compilation of a learner corpus, which is much needed in our research and teaching context, highlighting the benefits of constructing this type of corpus for understanding learners’ needs and making pedagogical decisions based on solid data. Subsequent sections will address the literature that underpins our work, the methodological approaches taken to compile the academic English learner corpus, and the studies derived from CorIFA.
The study of non-native varieties of English, which outnumber native-speaker varieties, is a key focus in learner corpus research (LCR), an umbrella term used to describe interlanguage investigations based on corpus linguistics. A corpus, defined as a collection of language texts in electronic form, is compiled according to specific criteria to represent a language or language variety. Corpus compilation involves establishing precise criteria for factors such as mode (e.g., written), type (e.g., research article), domain (e.g., academic), language or language varieties (e.g., learner English), text location (e.g., compiled in Brazil), and text production dates (e.g., from 2015-2020). Corpus linguistics, focusing on describing language use, utilizes various linguistic software tools to enable both quantitative and qualitative analyses of learner language. Its advantages include the ability to handle large amounts of data and the generalizability of results across similar groups, making a well-designed corpus representative of a population, as noted by Biber.
Any text chosen for analysis constitutes a sample, the representativeness of which hinges on its alignment with the diverse text types within the target population. Evaluating this representativeness necessitates a comprehensive delineation of the population the sample aims to mirror, alongside the methodologies employed to extract the sample from said population (Biber, 1993, p. 243).
A meticulous corpus design facilitates the generalization of results, as statistical tests are frequently employed to analyze the data. This section will emphasize learner corpus research, specifically examining their design characteristics and how they have addressed representativeness to facilitate comparisons across registers or groups.
Two of the largest learner corpora compiled in the 1990s, namely the International Corpus of Learner English (ICLE) and the Longman Learners’ Corpus (LLC), designed by Granger (1998), are noteworthy for their approach to language, task, and learner-related features as highlighted by Tono (2003). Language-related features in these corpora include mode, genre, style, and topic, with ICLE primarily consisting of argumentative essays on predefined topics and LLC containing essays and exam scripts on various subjects. Task-related characteristics encompass data collection methods, type of elicitation (spontaneous or prepared texts), production time (fixed, timed, or untimed), and allowance of references like dictionaries. In terms of learner-related features, ICLE comprises texts from university-level students, while LLC includes submissions from learners at different academic levels and first language backgrounds. ICLE predominantly features high-intermediate to advanced material, whereas LLC accepts texts from all proficiency levels. ICLE was the first to offer a large computerized learner data collection for research purposes, while LLC has been commercially available for research. ICLE has recently released an updated version with over 5.5 million words, whereas LLC, with 10 million words, lacks current information on their website (Tono, 2003; Granger et al., 2020).
Numerous learner corpus studies employ Contrastive Interlanguage Analysis (CIA), a method that involves comparing learner language with the target language (Granger, 2015, p. 13). The term 'Interlanguage Varieties' (ILV) has been used to describe learner language, emphasizing its highly variable nature (Granger, 2015, p. 18). This analytical approach may involve comparing students' oral or written texts with those of native speakers (ILV vs. NS) as seen in studies such as De Cock et al. (1998) examining word combinations in an English learner corpus of French as a first language compared to an English native speaker corpus. Other studies, like Altenberg & Tapper (1998), have explored interlanguage variety in relation to learners' first language and native speakers (ILV vs. L1 vs. NS), focusing on adverbial connectors in Sw-ICLE14, a Swedish as L1 corpus, and LOCNESS. Additionally, research by Bohórquez (2015) has delved into comparisons between two or more interlanguage varieties (ILV vs. ILV), specifically looking at lexical bundles in Ch-ICLE and Dt-ICLE.
The findings of CIA studies can enrich educators' comprehension of their students' requirements; however, teachers may opt to compile their own class corpus as a Do-It-Yourself Corpus (DIY corpus) or develop data-driven learning (DDL) activities based on existing corpora such as COCA, BNC, or their DIY corpus. It is important to note that DDL allows students to access corpus data and concordancing software as part of their language learning process. Using Sherlock Holmes as a metaphor, Johns (1997) illustrates that learners act as detectives, encouraged to investigate and identify grammatical rules, vocabulary meanings, collocations, and lexico-grammatical patterns. Following Johns' DDL format of "identify-classify-generalize," participants in Lee's (2011) study had the chance to study and practice prepositions through analyzing concordance lines. They delved into a corpus consisting of texts from J.K. Rowling's Harry Potter and the Philosopher's Stone, focusing on verb-preposition collocations. DDL exercises heightened students' understanding of preposition usage while aiding in deciphering the functions of specific phrasal verbs. DDL significantly contributed to students' language acquisition, proving to be an effective method for exam preparation by fostering a learning environment characterized by enthusiasm and student autonomy (Lee, 2011).
Researchers compiling their own corpus must adhere to stringent design criteria. Gilquin (2015, p. 16) emphasizes the importance of these rules, particularly in the context of learner corpora creation, where the diverse nature of interlanguage necessitates careful consideration. This critical aspect will be further elucidated in the subsequent section. Furthermore, there has been a dearth of studies focusing on students' texts generated within their specific classroom writing environments (Staples & Reppen, 2016), a gap that CorIFA endeavors to bridge by constructing a corpus from activities in "English for Academic Purposes." Through meticulous collection of learner metadata and thoughtful examination of task and language variables, as outlined in the forthcoming section, CorIFA facilitates comprehensive investigations into classroom contextualized learner writing.
Reppen (2010, p. 33) highlights that constructing a corpus demands a substantial time commitment due to the intricate series of procedures involved. This process encompasses tasks ranging from text collection to storage, markup, and metadata addition, presenting researchers with a multitude of decisions to navigate during corpus compilation. CorIFA, established in 2013 at a Brazilian public university, has undergone a detailed evolution in terms of its compilation history, challenges, and transformations, as outlined in this section. Throughout its development, the primary aim of the corpus has remained consistent: to delineate the written English interlanguage of Brazilian university students within a pedagogical framework.
The data collection process was initially influenced by the International Corpus of Learner English (ICLE). CorIFA and ICLE share similarities in terms of task variables, including task medium, genre, topic, and task setting. The compilation of CorIFA began with written tasks, specifically argumentative essays similar to those found in ICLE. Students were tasked with writing essays on predetermined topics like the internet, feminism, science, and technology. These essays were to be written either in class or at home and submitted via email. Notably, the essay length varied from ICLE, as CorIFA allowed for 200 to 300-word essays, contrasting with ICLE's requirement of 500 to 1000 words. In terms of learner variables, both ICLE and CorIFA participants shared similarities in age range and learning context, being university students who learned English in a non-English speaking environment. However, significant differences between the two corpora included first language, academic level, discipline, and language proficiency. While ICLE included texts from speakers of various languages, such as Chinese, Turkish, Portuguese, and French, CorIFA primarily consisted of Portuguese speakers. Initially, consent forms were in printed format and collected basic information like name and enrollment number. However, as the research group modified the consent forms to gather more metadata, texts collected in 2013 were subsequently discarded.
In 2014, an additional endeavor was made to gather student texts and establish a learner corpus. Given that the primary objective behind students writing texts was pedagogical in nature, numerous decisions were made by the subject teachers, resulting in the majority of essays being handwritten. However, due to the considerable time and effort required to convert these written texts into a digital format, the research group opted not to incorporate the 2014 texts into CorIFA. The group reasoned that, despite providing transcriber training, there existed potential risks of misspellings or grammatical errors being inadvertently altered during the digitization process, either by the transcriber or by computer spell checkers. This could potentially result in texts that did not accurately reflect the students' true English proficiency levels. Recognizing that the receipt of paper-based texts did not streamline the corpus compilation process, starting from 2015, texts have been exclusively collected in digital format, with students completing an online form.
In 2015, a collection of texts was gathered from students in both controlled and uncontrolled time settings. Initially, students submitted texts during in-class mock tests to assess their writing abilities under time constraints and with a given topic. Three mock tests were conducted for B1 and B2 level students, all featuring identical instructions for text production. The task required students to compose a minimum 300-word essay on a specified topic within a 30-minute timeframe. The transition to digital text collection proved successful, leading to a standardized compilation process. Starting from 2016, students have been submitting texts with varying registers via online forms, categorized by their proficiency levels as outlined in Table 1. This systematic corpus compilation has enabled the research group to maintain a robust learner corpus, which will be detailed in the subsequent section. Prior to text submission, learners are prompted to complete a digital form using Google Forms, providing their details and consenting to participate in the research by agreeing or disagreeing with the terms outlined in the consent form. This form is structured to assist researchers in documenting participants' social and linguistic backgrounds, as well as the specifics of the task. The consent letter template is included in the Appendix for reference.
The Corpus of IFA (CorIFA) comprises texts authored by undergraduate and graduate students enrolled in various courses at the Federal University of Minas Gerais. These students are participants in one of the five English for Academic Purposes (IFA) subjects established in 2012 as part of a broader strategy to bolster and enrich the university's internationalization efforts. Students enroll based on their proficiency levels, which span from intermediate to advanced (B1-C1), aligning with the Common European Framework of Reference for Languages. As a component of the evaluation process for each subject, students at different proficiency levels are tasked with producing texts tailored to specific academic registers (refer to Table 1). Prior to admission to an IFA subject, students' proficiency levels are assessed. This assessment can be fulfilled by submitting scores from a recognized proficiency test like TOEFL or IELTS, or by undertaking an internal placement test.
The corpus encompasses a variety of academic registers ranging from statement of purpose to research paper. Students compose these texts as part of their coursework, adhering to the guidelines provided by their instructors regarding word count and subject matter. The distribution of registers is progressive, commencing with tasks such as statement of purposes or summaries in IFA I and culminating in a research paper or literature review for IFA V. Following the submission of initial draft texts, instructors tailor their teaching of the specific register to address the needs of their students. Each curriculum includes multiple exercises on various registers and allows for text revision. Subsequently, students submit revised drafts, which are then edited and assessed. In compiling the corpus, the texts are categorized into unedited and edited versions.
One of the text variables considered in CorIFA is the length of the text in words. IFA teachers have the flexibility to establish word ranges for texts based on their familiarity with the students' proficiency levels and the characteristics of the register. The average word length is detailed in Table 2, which also provides information on the total number of words within each register and across the entire corpus.
The corpus, as depicted in Table 2, reveals significant variations in word average length across registers, encompassing six written registers with lengths ranging from 225.39 to 1,564.50 words. Notably, the research article emerges as the most extensive register in terms of word count, underscoring the diverse linguistic characteristics inherent in registers, influenced by factors such as physical mode, setting, and production circumstances (Biber & Finegan, 1994). Certain registers necessitate a greater word count due to their inherent nature. For instance, the research article, following the standard four-part organization (Introduction, Methods, Results, and Discussion - IMRD) outlined by Biber and Finegan (1994, p. 131), inherently demands a higher word count owing to the inclusion of multiple sections. Conversely, the shortest text type produced by CorIFA participants was the abstract, which serves as a concise summary of a research article, encapsulating its objectives, methodology, findings, and conclusions. Abstracts, often subject to word limits imposed by journals and conferences (Swales & Feak, 2009), necessitate writers to be succinct in their communication.
Another crucial consideration during corpus compilation was the inclusion of texts corresponding to different academic levels, taking into account the learner variable, as participants could be either undergraduate or graduate students (refer to Figure 1). Given that the IFA subjects are elective, students from both academic levels have the opportunity to enroll.
Since the first semester of 2016, there has been a noticeable increase in the number of collected samples compared to the previous year, a trend that persists to this day. The lower number of samples in 2015 can be attributed to the compilation process, which involved mock tests as mentioned earlier. It is important to note that not all students completed the task, some did not provide consent for their texts to be included in the corpus, and certain texts did not meet the minimum word requirement. Consequently, a smaller number of texts were eligible to be included in the corpus.
The corpus contains the largest number of samples from students enrolled in courses within the Physical Sciences and Engineering as well as the Biological and Health Sciences disciplines. In contrast, Humanities and Arts represent the discipline area with the fewest samples, as illustrated in Figure 2. This distribution is likely a result of the significantly lower total number of students in Humanities and Arts, as well as Social Sciences and Education, enrolled in English for Academic Purposes disciplines compared to those in the Biological and Hard Sciences fields.
Another significant aspect concerning the corpus design is its potential for longitudinal studies, enabling researchers to gain insights into the correlation between students' writing progression and their proficiency levels. The scarcity of learner corpus studies from a longitudinal viewpoint is notable, with few exceptions such as Biber et al. (2020), Goutéraux (2013), Littré (2015), and Meunier & Littré (2013). By 2019, a total of 217 students had submitted texts over multiple semesters, with 197 contributing for a year (two semesters) and 20 for more extended periods (3 semesters or more). Notably, the CorIFA data may include submissions from students who initially enrolled in IFA classes as undergraduates and continued their participation upon entering a graduate program.
Compiling a learner corpus in a pedagogical context has presented challenges due to evolving data collection procedures over the past few years, as detailed. Following the establishment of consistent compilation parameters, the corpus has exhibited steady growth. The varying task and learner variable complexities inherent in the corpus offer numerous avenues for investigation, some of which will be elucidated in the subsequent section.
In this section, we examine the background of studies utilizing CorIFA in their research. Over the past six years, since its inception, the corpus has served as a valuable linguistic database for Brazilian researchers. Thus far, research has predominantly focused on describing learners' language and comparing learners' written interlanguage with data from other corpora using CIA (as discussed in section 2). Centered on argumentative essays and abstracts, these studies delve into understanding learners' English usage across various proficiency levels and identifying instances of underuse or overuse of specific linguistic elements. The majority of studies utilize a reference corpus comprising well-assessed essays by non-native speakers or texts by native speakers. Topics explored include linking adverbials, collocations, that-clauses, conjunctions, noun phrases, and passive constructions. For clarity, we first present an overview of a descriptive study followed by five investigations falling within the CIA framework. This section concludes with a CorIFA-based study emphasizing a pedagogical intervention, prompting considerations on the practical applications of learner corpus research.
Queiroz (2019) delves into CorIFA to examine the use of noun phrases by novice writers, a common feature in expert academic texts such as research articles (Biber et al., 2009; Parkinson & Musgrave, 2014; Gray, 2015; Biber & Gray, 2016). The study scrutinizes the grammatical complexity of noun phrases (NPs) by analyzing general and specific topic essays from a CorIFA subcorpus, offering a detailed account of pre and post-modification types: adjective + noun and noun + prepositional phrase. Notably, the analysis of upper-intermediate level texts in the subcorpus surprisingly revealed a higher prevalence of complex NPs (59.3%) compared to simple ones (35%). Moreover, NPs were more prevalent in specific topic essays, indicating positive writing practices as complex NPs align with academic registers. This suggests that Brazilian learners at a B2 proficiency level, immersed in an academic writing context and exposed to specialized English texts in their disciplines, can adeptly employ structurally complex and concise phrasal structures typical of professional academic writing. The findings underscore the significance of discipline-specific tasks in fostering university-level writing suitable for academic contexts. This research underscores the value of descriptive corpus-based studies in contributing to applied linguistics, particularly in EAP. The corpus design revealed that task specificity (specific versus general topics) significantly influenced NP usage among Brazilian upper-intermediate level university novice writers.
Three CIA studies conducted using CorIFA focus on learners' utilization of conjunctions, recognized as pivotal elements for text coherence (Halliday & Hasan, 1976; Chen, 2006; Liu, 2008; Zihan, 2014). However, these linguistic elements are not universally necessary and require discerning application (Altenberg & Tapper, 1998, p. 80), presenting challenges as they exhibit variations across languages and cultures (Altenberg & Tapper, 1998, p. 81). Dutra et al. (2017 and 2019) and Santos (2008) analyzed a CorIFA subcorpus of B1 level argumentative essays, comparing it with LOCNESS. While these studies focused on different types of conjunctions - Dutra et al. (2017) examined addition words (besides and also), Dutra et al. (2019) explored result markers (thus, so, and therefore), and Santos (2018) investigated contrasting connectors (but and however) - they all identified significant quantitative disparities (underuse or overuse compared to LOCNESS or MICUSP), discrepancies in sentence positioning, and deficiencies in discourse function among learners. For example, the marker "so" is utilized three times more frequently in CorIFA than in LOCNESS, often serving to introduce a topic or signal the repetition of an idea (Dutra et al., 2019), functions commonly associated with oral discourse markers (Carter & McCarthy, 2006). A common interpretation across the three CorIFA studies is that learners' excessive use of conjunctions at the beginning of sentences highlights the need for improved register awareness in the Brazilian university setting.
Two other CorIFA CIA studies focused on the use of verbs. Guedes (2017) examined the most common academic verbs found in argumentative essays in CorIFA, comparing their usage to the British Academic Written English corpus (BAWE). Meanwhile, Nunes and Orfanò (2020) analyzed verbs in research abstracts within the framework of transitivity in passive that-clauses, contrasting the results from the learner corpus with a Lingua Franca Corpus composed of abstracts from both soft and hard sciences. The comparison revealed a lack of variation in action verbs and a low frequency of adverb + verb collocations in CorIFA essays compared to BAWE, indicating Brazilian learners' unfamiliarity with the academic register (Guedes, 2017). In terms of abstracts, Nunes and Orfanò (2020) also noted inadequacies in the learners' verb choices. Learners tended to use more mental verbs like "conclude," "verify," and "assume," whereas expert writers favored relational verbs such as "show," "demonstrate," and "reveal." Additionally, learners often omitted the conscious agent, creating a sense of detachment from the discussed findings. In contrast, researchers demonstrated a more active awareness of the object of study, asserting greater intellectual authority. The development of authorship is a crucial skill that should be integrated into EAP classes, and insights from corpus-driven linguistic analyses like this one and the study on verb variation and collocations can offer valuable guidance to teachers in their instructional practices.
The preceding studies conducted with our learner corpus have demonstrated the valuable insights that specific corpus analysis can offer in understanding learners' linguistic requirements, taking into account factors such as the register in which they write, their proficiency levels, and the nature of the tasks they undertake. The overarching objective of such research endeavors is to address learners' precise challenges, enabling the development of more tailored activities and the revision of course syllabi. An exemplary instance of integrating interlanguage analysis with classroom practices was exemplified in the work of Alves and Pinto (2018). Their study delved into the reporting of results and conclusions in abstracts within two apprentice corpora, namely CorIFA and MICUSP. The analysis of CorIFA yielded authentic instances of learner language, while access to MICUSP facilitated a pedagogical approach to corpus linguistics known as Do-it-Yourself (DIY) corpora (McEnery et al., 2006). Through this method, students curated their own study corpus, enhancing their awareness of ways to enhance subsequent abstract drafts. MICUSP proved to be a fitting choice for DIY endeavors due to its repository of well-evaluated university papers, and the online platform's flexibility in selecting discipline-specific texts.
The future agenda holds promise, encompassing advancements in research methodologies, improved access to students' interlanguage, longitudinal studies, and the description of variations across registers and disciplines. It is crucial to emphasize the integration of Data-Driven Learning (DDL) activities (Johns, 1991) into language classrooms, elucidating their benefits and constraints, and facilitating the translation of research findings into practical applications, as demonstrated by Almeida et al. (in press).
The primary objective of this paper was to elucidate the rationale for constructing an academic learner corpus, emphasizing the significance of this endeavor in uncovering manifestations of learners' written interlanguage. The fundamental principles governing corpus compilation were delineated, along with the design criteria implemented for CorIFA. Subsequently, the methodological procedures employed in the compilation process were outlined. The composition of texts within the corpus and the register linked to the students' proficiency levels were elucidated, thereby suggesting a diverse array of topics for prospective investigations.
Following this, descriptive and contrastive interlanguage analysis (CIA) research utilizing data from CorIFA was showcased to demonstrate the valuable insights the corpus has offered to researchers studying learner interlanguage. The highlighted studies in this paper further support the assertion that creating and analyzing a learner corpus can significantly benefit language educators seeking to deepen their comprehension of learners' language production, empowering them to make informed pedagogical choices in their teaching practices.
This article presents research conducted by the Grupo de Estudos em Corpora Especializados e de Aprendizes (GECEA), focusing on specialized corpora and learner corpora.