In this study, a novel method is proposed for constructing self-aware data structures through online machine learning. The research introduces a new category of data structures termed Smart Data Structures, which continuously and autonomously enhance themselves to simplify the complexity of manual data structure modifications across various systems, applications, and workloads. The study also concludes that online machine learning proves beneficial for autonomous data structure adaptation. A reinforcement machine learning algorithm is proposed for online machine learning, leveraging a reward system to optimize parameters effectively. Online learning, in the author's perspective, provides a reliable and efficient framework for evaluating intricate dynamic tradeoffs. The utilization of intelligent multicore data structures can potentially alleviate many of the challenges programmers face in their daily tasks.
The complexity of programming is on the rise with the increasing prevalence of multicores. Programmers invest significant effort in parallelizing tasks and optimizing their allocation on hardware to ensure all threads remain active and collaborate effectively. A major design challenge in numerous applications lies in efficiently managing thread cooperation through shared data structures. The selection of parallel data structure methods and algorithm parameters has become increasingly critical for application performance. Factors such as the design of the machine's memory system and application-specific considerations, like the load on the data structure, can significantly impact the optimal choices of methods and parameters. Complicating matters further, many programs involve input-dependent processing, leading to dynamic changes in the workload.
Self-aware computing has emerged as an automated approach to alleviate the burden on programmers. These systems are designed to autonomously monitor themselves and adjust their behavior dynamically during runtime, unlike traditional systems that require manual intervention to balance system constraints. Utilizing closed-loop optimization, self-aware systems strive to achieve optimal performance by continuously measuring feedback and adapting to changing system conditions. They find application across diverse platforms such as embedded systems, real-time environments, desktops, servers, and cloud computing setups, often referred to as autonomic, auto-tuning, or adaptive systems. A critical and challenging aspect lies in designing these systems to effectively coordinate threads through a shared data structure for efficient operation. The choice of the most effective algorithm and parameter settings is heavily influenced by the memory system architecture of the machine, tailored to the specific application requirements (Conradihoffmann and Frohlich, 2021). Given the complexity involved, manual coding for programmers can be overwhelming, leading to the development of input-dependent applications that dynamically distribute workloads to optimize performance across various inputs and machines.
This research introduces a novel category of self-aware parallel data structures termed as "Smart Data Structures." These structures possess the capability to autonomously optimize themselves by leveraging state-of-the-art techniques rooted in online machine learning. By incorporating these advanced mechanisms, Smart Data Structures alleviate the burden on programmers, eliminating the need for manual adjustments to achieve peak performance across diverse computing environments, applications, and input scenarios.
Standard data structures can be enhanced by integrating smart data structures that possess self-optimizing capabilities. This enhancement involves overlaying a conventional data structure with an online learning engine. For instance, the comparison between the fundamental framework of a typical data structure and that of an intelligent data structure will be detailed in the following section.
The components of a typical data structure are illustrated in Figure 1, comprising algorithms, an interface, and data storage. Data organization is facilitated by storage, the interface specifies the actions threads can perform on the data for modification or querying, and algorithms implement the interfaces while upholding accurate concurrent semantics. Parameters such as thresholds used to regulate storage and algorithms are referred to as knobs (Rosa et al., 2019), often initially set with universal static defaults by the library programmer. When default settings prove inadequate, programmers must manually adjust these knobs, a process typically involving trial and error that can prolong development and compromise code readability (Hoffmann, 2020). Despite its critical importance, the complexity of runtime tweaking often leads programmers to overlook this aspect.
Smart Data Structures, as illustrated in Figure 2, adhere to consistent storage, interfaces, and methods. What sets Smart Data Structures apart is the integration of an online learning engine into traditional data structures, enabling automatic and dynamic adjustment of parameters to optimize storage and algorithmic performance. In response to system modifications or input changes affecting these tradeoffs, Smart Data Structures effectively balance complex tradeoffs to determine optimal knob settings (Pagani et al., 2018).
Smart Data Structures represent a significant departure from previous studies in the field. While earlier research has demonstrated the capacity to adapt to diverse machine architectures and runtime scenarios, often relying on thresholds established during compile-time or install-time characterization, the challenge lies in the fact that these characterizations may not accurately reflect actual runtime conditions in modern systems. Smart Data Structures, on the other hand, employ an online approach that continuously gathers real-time data on system dynamics and performance trade-offs. Through online learning mechanisms, they are able to dynamically balance these trade-offs during runtime, thereby optimizing performance. By effectively responding to changes in the system, program, or inputs, Smart Data Structures aim to achieve the highest possible performance levels.
Internally, a Smart Data Structure leverages online machine learning to adaptively learn optimal knob settings for storage and algorithms. Each Smart Data Structure is connected to an online learning engine dedicated to optimizing its knobs, operating in a separate learning thread from application threads. The quantity of learning threads can be adjusted as needed. Optimization within these learning engines is guided by performance feedback, known as the reward signal, which must accurately reflect application performance without causing disruptions (Iranfar et al., 2019). This study introduces a prototype of smart data structures capable of self-adjustment through online machine learning techniques.
In the preceding section, we established that an online machine learning algorithm is employed to oversee and regulate the knob settings for the Smart Data Structures. Now, let us delve into the operational mechanics of the Online Machine Learning algorithm.
The Reinforcement Learning (RL) method utilized by our proposed Smart Data Structures involves interpreting a reward signal with the objective of maximizing it. To achieve this, I have opted for an average reward optimality criterion and have implemented policy gradients to train an efficient policy. This choice was made to ensure that the algorithm we develop is not only fast enough for online applications but also capable of handling significant partial observability. Specifically, we have employed the Natural Actor-Critic method. In this context, a policy represents a conditional distribution over "actions," and the primary goal of policy gradients is to improve a policy based on a given state. At each timestep, the agent selects a sampled action from this policy. These actions consist of discrete-valued scan counts, with each count corresponding to a Smart Data Structure such as the Smart Queue, Pairing Heap, and Skip List. Executing the appropriate scan count in its respective Smart Data Structure constitutes the action taken by the agent.
I determine the average reward obtained by executing a specific policy as a measure of its effectiveness. This average reward, derived from following the policy's instructions, is dependent on its parameters. The standard reward calculation is expressed as: ùúÇ(ùúÉ) = Œï{ùëÖ} = lim ùëñ‚àí0 1/ùëñ‚àëùëüùë° ùëñ ùë°=1, where rt represents a particular reward at time t, gathered from the collective throughputs of all Smart Data Structures or an external monitor, smoothed over a short time frame, and R is a random variable denoting reward. Due to the fact that different configurations lead to unique action distributions, and as various actions influence the evolution of the system state over time, the average reward is inherently tied to the parameters at play.
Our solution introduces an additional thread to the program to manage the learning engine, aiming to reduce interruptions to the program and enable background optimization while it runs. However, the use of a second thread involves a trade-off as the program could have utilized this thread for parallel processing. The justification for adding the extra thread lies in the net performance improvement it brings. The learning thread functions as a distinct, dedicated entity that operates autonomously from the application's existing threads. The primary objectives of this approach are to swiftly create knob optimizations and adapt to sudden system or application changes that may necessitate adjustments to the optimal knob settings over time.
Fortunately, achieving net gains in common scenarios is relatively straightforward. Although several auto-tuning libraries have explored the realm of offline machine learning for static tuning, Smart Data Structures stands out as the pioneering work in successfully applying online machine learning. This approach proves to be a potent optimization strategy for adaptive data structures. Additionally, I introduce a novel learning algorithm rooted in Policy Gradients Reinforcement Learning, which not only delivers high performance but also demonstrates efficiency suitable for online implementation in adaptive data structures.
This study introduces a novel method for designing self-aware data structures using online machine learning. The approach introduces a new category of data structures termed Smart Data Structures, which continuously and autonomously adjust themselves to streamline the process of manually configuring data structures for diverse systems, applications, and workloads. The methodology advocates for the utilization of online learning to enhance other systems, highlighting its efficacy. A reinforcement machine learning algorithm is proposed for the online machine learning process, leveraging a reward system to optimize parameters accordingly. The author asserts that online learning offers a dependable framework for assessing intricate dynamic trade-offs, playing a pivotal role in shaping future systems. The implementation of Smart multicore data structures has the potential to mitigate numerous challenges faced by programmers in their day-to-day operations.