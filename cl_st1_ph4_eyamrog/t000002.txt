This article presents a theoretical work whose objective is the discussion of methodologies 
and methods in educational research, in particular those that analyze classroom discursive interactions. 
The first part discusses the two main research paradigms and their ontological and epistemological bases: 
positivism and interpretivism. Next, two methods for analyzing discursive interactions are presented and 
discussed, one for each paradigm. Systematic coding - within the quantitative context - is indicated to 
treat data from large samples, to describe general patterns and, by transforming the discourse into 
variables, to statistical comparisons or temporal analyses. The method is applied in a set of 42 episodes 
of group dialogue and the results are discussed in light of the nature of the research questions, showing 
what types of statistical tests can be performed. Within the interpretivist paradigm,  sociocultural 
discourse analysis is presented as an example of qualitative method an it is applied to excerpts from 
classroom dialogues. The main finding is the identification of typologies that describe the ways in which 
teacher and students construct scientific explanations. In the final part, some possibilities and limits of 
each method are discussed and the conclusion defendes that both can be seen as complementary for the 
advancement of knowledge in the educational field. 

Much research has focused on the role of language and discursive interaction in the 
knowledge-building process in classroom-based settings (Howe & Mercer, 2007; Mercer et al., 2020; 
Resnick et al., 2015; Schwarz & Baker, 2016). In the last 40 years, this research field has flourished under 
umbrella terms such as ‘classroom dialogue’ or ‘dialogic teaching’ (Kim & Wilkinson, 2019; Mercer & 
Dawes, 2014), encapsulating studies that aim to effectively use discursive interactions in the teaching 
context (Alexander, 2008). This stance in the educational field has been called ‘dialogic turn’, emphasising 
students’ voice, agency, and participation in the co-construction of knowledge (Wilkinson & Son, 2011). 

The first large-scale study on classroom dialogue was probably Flanders’s (1970), who 
depicted the two-thirds rule; that is, in regular classes, two-thirds of the time is filled by talk; two-thirds 
of this talk is teacher’s talk, and two-thirds of this teacher’s talk is lecturing. Another relevant finding is 
framed in the triadic discourse: initiation, response, and feedback or evaluation (Mehan, 1979; Sinclair & 
Coulthard, 1975). This pattern is possibly the most common feature in whole-class talk and can account 
for up to 70% of all teacher-student interactions (Cazden, 1988; Nassaji & Wells, 2000; Wells, 1993). 
Although much of these studies have taken place in Anglo-Saxon countries, this pattern is recognised 
worldwide (Alexander, 2001). 

Interventionist research has investigated and identified forms of enhanced teacher-student 
interactions that support teaching and learning (e.g., Mercer, 2002). Perhaps the main conclusion is that 
forms of talking have profound implications for what is made available to learn (Howe & Mercer, 2007; 
Kelly, 2014; Lemke, 2001); “the quality of student learning is closely linked to the quality of classroom 
talk” (Nystrand, 1997, p. 29). 

More recently, review books on methods for analysing classroom dialogue have been 
published (Kershner, Hennessy, et al., 2020; Kumpulainen et al., 2009; Märtsin, 2012). Contributing to 
this proliferating field of research, the proposal of this discussion paper is to reflect on the methodologies 
and methods to analyse classroom discursive interaction. However, instead of directly departing to 
analytical methods, it is firstly offered a broad methodological discussion starting from research 
paradigms that considers elements such as epistemology and ontology. In the second part of this paper, 
methods and procedures for discursive data analysis are presented in two veins: quantitative and 
qualitative approaches. Both methods are discussed and illustrated based on examples from previous 
research. 

There is a usual view that relates methodology with the selection of methods (techniques) 
for a study and their application for data analysis. However, a far more comprehensive notion of 
methodology comprises the researcher’s attachment to different epistemological and theoretical 
traditions that influence not only the selection of methods, but also the framing of research questions 
and design (Mercer et al., 2004; Taber, 2012, 2013; Treagust et al., 2014). 

Crotty (1998) argues that a research conceptualisation should entail four elements: 
epistemology, theoretical perspective, methodology, and methods. Taber (2013) considers similar 
elements when referring to ontological and epistemological assumptions in research: theoretical 
perspective, methodology, research design, and the coherent employment of techniques for acquiring 
and analysing data. 

These elements jointly create what is often called the research paradigm, a worldview or basic 
belief that sets the value of research and guides the investigator not only in the choice of methods but 
also in some fundamental assumptions (Guba & Lincoln, 1994; Treagust et al., 2014). In other words, 
the research paradigm is seen as a ‘reference point’, ‘vision’, or ‘philosophy’ that amalgamates beliefs, 
values, and methodologies in research (Taber, 2013; Treagust et al., 2014). In practice, paradigms are how 
the researcher thinks about and makes sense of their study.  

Different paradigms can employ very contrasting aspects, most fundamentally when 
considering the two broadest perspectives. The first paradigm is positivist, nomothetic, and 
confirmatory, which means that it deals with definitive and objective knowledge, seeks general patterns 
or laws, and tests hypotheses. The underlying assumption is that “it is possible to report unambiguous 
truth, in terms of observable phenomena and verified facts” (Taber, 2013, p. 49). Guba and Lincoln 
(1994) pointed out that this approach is grounded in realistic ontology and objectivist epistemology. 
Realistic ontology entails that “an apprehendable reality is assumed to exist, driven by immutable natural 
laws and mechanisms” (p. 109), whereas an objectivist epistemology assumes that “the investigator and 
the investigated ‘object’ are assumed to be independent entities, and the investigator to be capable of 
studying the object without influencing it or being influenced by it.” (p. 110). This approach to social 
science is deemed objectivist and determinist because it sees human beings as products of the 
environment and responses to it (Cohen et al., 2007). 

In more detail, positivist research “strives for objectivity, measurability, predictability, 
controllability, patterning, the construction of laws and rules of behaviour” and seeks causal explanations 
to produce claims (Cohen et al., 2007, p. 26; Treagust et al., 2014). Within this context, quantitative 
methods are more aligned with such a perspective, trying to capture social reality through predesigned 
categories and measurements as well as providing causal-effect explanations. 

The second paradigm is interpretivist, idiographic and involving discovery. As knowledge 
(or nature) is viewed as an inherently subjective human interpretation, this paradigm focuses on specific 
and contextual cases. It deals with “meanings that those participating in educational situations give to 
what they experience” (Taber, 2013, p. 52). Researchers under this paradigm believe that meanings are 
not pregiven but co-created through interaction. Therefore, they might engage with participants in 
activities and seek their views (Treagust et al., 2014). Guba and Lincoln (1994) said that this approach is 
grounded in a relativist ontology and subjectivist epistemology. Relativist ontology conceives that 
“realities are apprehendable in the form of multiple, intangible mental constructions, socially and 
experientially based” (p. 110). In contrast, a subjectivist epistemology denotes that “the investigator and 
the object of investigation are assumed to be interactively linked so that the ‘findings’ are created as the 
investigation proceeds” (p. 111). In this approach, human beings are seen as agents of their own actions 
and producers of their own environment. Because of this, this perspective is deemed subjectivist and 
voluntarist (Cohen et al., 2007).  

Thus, interpretive researchers “strive to understand and interpret the world in terms of its 
actors” (Cohen et al., 2007, p. 26) and frame the situated meaning of human experience (Treagust et al., 
2014). Employing mainly qualitative methods, such tradition interprets social situations when 
constructing meanings from the data. 

There is criticism about both paradigms. Positivist researchers might be seen as superficial 
and limiting, as they do not grasp the inner contradictions and assume that the same finding or solutions 
can be applied in every context (Taber, 2013). At the same time, interpretivist studies have sometimes 
been critiqued for being anecdotal or not methodically rigorous, resulting in a lack of generalisation or 
scalability. 

Notwithstanding the above, some researchers consider critical theory to be a third research 
paradigm (Cohen et al., 2007; Guba & Lincoln, 1994; Treagust et al., 2014). Researchers following this 
tradition emphasise the political and ideological stances in human interaction, arguing that factors such 
as power and inequality shape and forge the ways that human beings live, behave and perceive reality 
(Cohen et al., 2007).  

The existence of many research paradigms might not be a problem in itself, especially in 
educational research. Treagust and colleagues (2014) advocate that this diversity promotes the 
construction of more balanced knowledge and broader effort. In same position, Taber (2013) 
acknowledges that any paradigm has strengths and limitations, thus any of them can produce valuable 
knowledge and can be employed in complementary ways.  

At this point at least three aspects must be considered in relation to the adoption of a research 
paradigm. First, it must provide a consistent and coherent account across every step of the study (Taber, 
2013, p. 55). Second, different paradigms have different purposes and methods that must lead to different 
outcomes (p. 68). Third, and finally, any study refers to a paradigm, if it is not explicit, it is implicit in the 
manner that the research questions are framed and addressed (p. 68). These concerns stress the 
importance of thinking carefully on the relationship between the research aims and the most 
appropriate methods to find them.  

Surely, all paradigms can be applied and generate new knowledge when analysing classroom 
interaction. For instance, the positivist approach demands simplification of social practices to make 
research manageable; in general, selecting a set of dialogue variables and controlling others one related to 
learning outcomes (Asterhan et al., 2020). It is such a method that allows us to state something about 
how dialogic teaching affects students' learning. On the other side, the interpretivist paradigm might 
provide a more nuanced frame on the dynamics of dialogue through, for example, ethnographic case 
studies that stretch the cultural context of the classroom setting (Asterhan et al., 2020). However, as said 
above, different methods are required for each paradigm when addressing research questions of different 
natures. Ultimately, this is exactly the aim of this discussion paper. 

For didactic purposes, the next sections are divided into quantitative or qualitative 
methods. For each of them, there is a brief presentation of one analytical procedure and its application to 
real classroom discursive data from a previous project. The research questions and findings are presented 
here just as an exemplary model of operationalising paradigms and methods. Thus, the goal is not to 
discuss the new knowledge on dialogic teaching generated from this data. 

First of all, analysing discursive interaction is an inherently subjective exercise of building 
meaning from the thoughts and voices of others, which are constrained and affected by social, 
cultural, and situated contexts. Such analytical process involves a great deal of interpretation as it relates 
to reflexivity; researchers bring their own preconceptions, interests, biases, agenda, and so on (Cohen et 
al., 2007). 

Researchers have also discussed competing tensions between ‘deductive’ and ‘inductive’ 
approaches in analysing data (Evans, 2013; Taber, 2013). While the former looks for evidence in relation 
to pre-established themes, which undoubtedly steers analysis, the latter stems from open-minded inquiry, 
generates themes from the data and uses them as an analytical tool (Evans, 2013). In other words, the 
analysis can be drawn from the conceptual framework or be grounded in data (Taber, 2013), but both 
cases involve instances of creating categories, grouping them under higher-order headings, and 
formulating a general description of the research topic (Elo & Kyngäs, 2008).  

Despite there being many approaches to analyse discursive data and interaction, it might be 
argued that all of them assume that the researcher must “reflect on them [data] repeatedly and at length, 
to be able to fragment and manipulate them in the search for underlying patterns and meanings” (Evans, 
2013, p. 158). The extension in which the data is fragmented may define the use of quantitative or 
qualitative methods. It is considered that when analysing discursive interaction, in most cases there is a 
moment in which the researcher will categorise or ‘code’ an utterance, turn of speech or episode 
(Hennessy et al., 2020). 

Below, two examples are provided. The first is an illustration of a quantitative analysis 
regarding small-group dialogue during seven different tasks. The second is a qualitative analysis carried 
out in episodes of whole-class teaching about the topic of evaporation. 

In this section, we focus on the systematic coding method, as it is the most popular among 
researchers and examines interaction as a turn-taking system and categorises each of them. Within this 
method, the analytic process of discursive data involves the reduction of the data through the marking of 
relevant points about what is looked for. Very frequently, this procedure is called ‘coding’ and enables 
the researcher to “organise and structure the data” at the same time that “translate raw data into particular 
conceptual references” and then “identify links to the different categories” (Evans, 2013, pp. 158–159). 
Objectivity is a key aspect of systematic coding as it encompasses the development of a scheme that 
needs to be unambiguous; that is, the criteria for coding must be clear enough so that different observers 
assign the same code/category to the discursive unit (Galton et al., 1980). Quite frequently, codes come 
from a theoretical framework or previous research. In this case, this research may be labelled as ‘template’ 
since the analytical framework is informed by the theoretical perspective, “so that the analyst knows just 
what they are looking for in  the data from the start” (Robson, 2002; Taber, 2013, p. 293). 

When the codes' occurrences are counted, such a method provides a broad overview of data 
sample and allows the establishment of patterns within and across events (Snell & Lefstein, 2011). 
However, this technique is not free of problematic issues, as there is a trend to fragment the data and 
lose context or other meanings that are not captured in the codes (Cohen et al., 2007). Therefore, 
systematic coding might be seen as reductionist (Mercer et al., 2004; Snell & Lefstein, 2011). The next 
subsection shows an example of the kinds of research questions and findings that systematic coding 
might provide. 

In the research reported in Author (XXXX), there were three questions about group-work 
interaction, more specifically; 1) How can small-group dialogue in a Brazilian primary school 
be characterised? 2) How did it change over the course of the intervention? and; 3) Did the groups 
become more dialogic ? For context, the research project was based on a teacher professional 
development programme to promote dialogic talk both in small-group work and whole-class teaching. 

In total, 42 episodes of group talk were recorded, transcribed, and analysed. Due to the size 
sample and the nature of the questions, a quantitative analysis would be the most reasonable approach 
to find the general pattern of the discursive interaction that emerged in the groups and how such a pattern 
has potentially changed over time.  

A coding scheme was devised based on previous works from the literature and comprised a 
set of ten codes relevant to dialogic classroom talk at the utterance level. The resulting scheme contained 
ten categories divided into three contexts: content, task and off-topic that discriminate the utterance’s 
tenor. That is, the codes can be arranged to distinguish if the utterance is related to the content proposed 
in the task (topic under discussion); if it is related to task procedures or class management; or, ultimately, 
if it is off-topic, talk neither focused on content nor task (Table 1). 

The utterances that are related to the task content were classified regarding their discursive 
functions inspired in the IRF pattern and based on the dialogic features that describe productive talk 
(Howe et al., 2019). Thus, it was generated created six codes, two for each move of the triadic discourse: 
invitation (INV), dialogic invitation (D_INV), contribution (CON), dialogic contribution 
(D_CON), follow-up (FOL) and dialogic evaluation (D_EVA). This distinction was made only 
for content utterances because they are the medium in which knowledge construction and conceptual 
learning happen. 

The use of the term 'dialogic' tries to frame the utterances in which participants 
make significant contributions by moving ideas forward through critically taking account of others’ 
perspectives in building knowledge collectively (Kershner, Dowdall, et al., 2020; Mercer, 2003). Given 
the research interest, engagement in dialogic talk was operationalised by relatively frequent occurrences 
of the three dialogic codes.  

To conclude, this scheme made it possible to describe classroom talk and evaluate dialogicity; 
both goals were at the core of the research questions. Classroom talk could be described by comparing 
the relative code occurrences within each context (content, instruction, off-topic) and dialogicity 
evaluated by considering the frequency of dialogic utterances in relation to simple ones.  

This kind of positivist coding assumes that the codes can capture components or 
characteristics of the discursive interaction. Thus, aiming objectivism, the coding scheme was tested for 
inter-reliability purposes. Three Masters students to join the researcher in piloting and refine the scheme, 
establish coding rules, and achieve consistency.  

In the first round, all raters coded the same group-talk episode and discussed the scheme and 
rules for alignment and convergence. After moderate scores were obtained, the scheme was simplified 
by dropping some codes, and rules were clarified and written in more detail. Two raters coded 28% of 
the episodes (12 out of 42), and inter-rater reliability was calculated using Cohen’s Kappa scores through 
R (RStudio team, 2020). After the iterative process, an acceptable/excellent level of agreement was 
accomplished, as Cohen’s Kappa scores averaged K = .79 (Kappa values for each code are presented in 
Table 1). Then, the researcher finally coded the rest of the material .This procedure makes the scheme 
reliable. 

In addressing the first research question, the result is presented considering the entire dataset. 
Firstly, group talk as a whole was considered, and relative code frequencies measured the number of 
content-related (codes 1 to 6), instruction-related (code 7), and off-topic utterances (code 8) divided by 
the sum of all of them. Figure 1 shows that groups spent almost half (56%) of the utterances talking 
about the content of the task, around one-quarter negotiating the task-instruction (25%), and a reasonable 
number off-topic (19%). Only half of group work was devoted to content, which is the kind of talk was 
more directly related to conceptual-disciplinary learning gains. 

The data could be further explored by searching for variations in the codes’ frequencies 
across tasks (question 2) and using statistical analysis to find significant variances. The dataset was 
consistent for non-parametric tests to compare three or more populations (Fligner-Killeen’s test was 
above the significance level for all but the D_EVA code when comparing tasks or groups, p > 0.05). This 
result allowed non-parametric tests to analyse comparisons among groups employing the Kruskal-Wallis 
test and the post-hoc Nemenyi test. The ‘other’ and ‘inaudible’ codes were discarded and not considered 
for analysis. 

Figure 2 shows code distributions for contexts of group talk as a whole and discursive 
functions across tasks. Only a small number of significant differences between groups were found. For 
instance, the analysis for context showed a significant difference in content (H(6) = 17.575, p = .007) 
between Tasks 3–4 (p = .037) and Tasks 3–5 (p = .022), as well as in off-topic (H(6) = 14.007, p = 
.029) between Tasks 3-5 (p = .046). No difference was found in instruction. Broadly speaking, students 
talked more about the content and less off-topic in Tasks 2 and 3.  

In order to answer whether the groups became more dialogic (question 3), it was compared 
the aggregated results for non-dialogic utterances (the sum-up of codes 1, 3 and 5) with those considered 
dialogic (codes 2, 4 and 6). As the dialogic and non-dialogic measures are mirrored images, it suffices to 
conduct the statistical analysis for just one of them.  

There are just three task-pairs that show significant differences (H(6) = 24.881, p < .001); 
tasks 1-2 (p = .008), tasks 2-6 (p = .001) and tasks 4-6 (p = .04). In Figure 3, it can be seen that tasks 2 
was the most dialogic, followed by task 4, while tasks 1 and 6 showed moves with more non-dialogic 
utterances. Therefore, the hypothesis of enhancing the use of dialogic utterances throughout tasks was 
not confirmed. There were only a few differences between tasks that cannot be classified as an effect of 
the intervention. 

It is worth noting that these findings on classroom interaction were obtained without 
presenting any discursive extract to the reader. In some cases, researchers present just a small extract to 
illustrate the scheme application and not as part of the analysis itself. Thus, the result is totally based on 
the explanatory power of the codes and on the reliability of the coding process. Moreover, considering 
the nature of the questions, it is clear that a qualitative approach would neither offer the generalisation 
for the description nor objectivism to compare the change in the discursive variables over time.   

For example, Extract 1 shows an example of dialogic talk that did emerge in these groups: 
a episode carefully selected to illustrate how students interacted in high levels of dialogicity. The 
identification of such episode among the others was only possible after the systematic codification and 
frequency counting of the entire dataset. Quantitatively, more than half of the utterances was considered 
dialogic (17 out of 30; around 57%). For a brief comparison, the average of the dialogicity across the 
seven tasks was something around 33% (Figure 3).  

Qualitative methods underpinned by the interpretivism paradigm usually take into account 
the cultural and social context and practices that shape the classroom interaction (e.g., Gee & Green, 
1998). It is said that the knowledge is socially constructed through language. These methods can include 
linguistic ethnography, sociolinguistics, discourse analysis among others (Hennessy et al., 2020). In most 
cases, they stress the contextual and sociocultural dimensions rather than the verbal exchange per se (turn-
taking) mainly because discourse is framed in a broad sense: "the text (speech, writing, or image), the 
discursive practice of analysis within the text, and the social practices and structures bound to notions of 
power and knowledge." (Gregory, 2020). 

Researchers dealing with discursive data and qualitative methods employ a variety of 
procedures such as identifying themes, generating units, classifying and categorising these 
units, structuring narratives to describe content, interpreting scenarios and constructing theory (Cohen 
et al., 2007; Robson, 2002). 

As an example of qualitative method, sociocultural discourse analysis is presented and 
applied to trace relationships between classroom interaction and conceptual learning. Such analysis 
consisted of closely examining the episodes aiming at generating categories and illustrating them with 
selected extracts. This focus enabled researchers to search not simply for a specific discursive function 
but to investigate whole forms of interactions that can be used to generate typologies and evaluate their 
impact on particular educational purposes. In addition, this method deals with language “content, 
function, and the ways shared understanding is developed in social context, over time” (Mercer, 2010, p. 
9). 

One of the strengths of sociocultural discourse analysis is that “the actual talk remains the 
data throughout the analysis and so the processes of the joint construction of knowledge can be examined 
in detail” (Mercer, 2004, p. 143). Thus, here, the focus is not the discursive functions or the language 
itself but the content of talk and the pursuit of joint intellectual activity (Mercer, 2004). It is an inductive 
approach to inquiry from which themes or categories should emerge from the data (Evans, 2013; Taber, 
2013).  

Such analysis is often illustrated by selected extracts followed by a commentary with 
reference to prior knowledge of both the field and the context. It can be concerned with the syntax and 
the cohesive structure of language to represent the ways that knowledge is socially built in the classroom 
(Mercer, 2004). As dialogue remains untouchable throughout the analysis, the emerged typologies offer 
a heuristic device for making sense of the talk in relation to one particular issue (Mercer, 2004). For 
instance, Mercer’s studies identified three types of group talk: disputational, cumulative, and exploratory; 
and verified that this last have a positive impact on student learning. Thus, the point is not to reduce the 
data to a categorical tally, but set broad features that involve the context and the discursive dynamic 
regarding an educational learning goal (Mercer et al., 2004). The next subsection shows an example of 
the kind of research questions and finding that sociocultural discourse analysis might provide. 

Again, the data comes from the same previous project that consisted of a classroom-based 
intervention to promote dialogue. The second module of the TPD programme was based on a predefined 
classroom material that included a considerable amount of student talking and thinking while allowing 
students to develop their own theories about water evaporation based on observations and everyday 
experiences (SPRinG, n.d.). 

A research question proposed to investigate how classroom talk supported students’ 
scientific understanding. It was argued that much of the conceptual learning in primary science occurs 
through the construction of explanations. Thus, the point here was to frame and analyse how teachers 
and students jointly construct the scientific explanation of evaporation through talk. 

However, defining what counts as an explanation or framing its structure is not an easy task, 
despite the consensus in taking it as an intellectual elaboration that accounts for a cause-effect relationship 
and uses a logical connective like ‘because’ connecting the cause and the result. Within this perspective, 
the corpus of data was read to search for structures that resemble scientific explanations. 

Considering the interpretivism nature of this analysis and the specificities of the study 
(primary science, scientific discourse and evaporation), a further framework was required during the data 
interrogation. Basically, it was required to define 'what counts as an explanation in classroom talk 
within primary science'. Very briefly, looking at the data and theory reiteratively, two structural aspects 
was set: forms of explanations and causation (Braaten & Windschitl, 2011). Thus, the analysis would 
search for sequences of utterances that convey instances of explanation (definitions, descriptions, and 
reasoning) and causation (cause-effect accounts of an observable event). Finding examples of these 
occurrences might make it possible to generate typologies, comment on and describe them, and discuss 
potential outcomes.  

Thus, the data corpus was analysed in order to select instances of explanations being built as 
a collective activity between teachers and students. In the 18 episodes of whole-class teaching recorded 
in this module, five types of explanatory sequences were elaborated and arranged into three broad 
discursive acts depending on whether teachers were exploring, guiding, or providing an explanation. 

No clear, straightforward distinction exists between the sequences of exploring and guiding 
explanations as real classroom interactions have unplanned utterances, deviations, and uncontrolled flows 
that make it hard to frame the sequences under a single category (Barnes, 1976). Thus, these kinds of 
explanatory sequences  should not be taken as neat or crystalline; different categories overlap in some 
utterances. Mercer (1995) already raised this concern when he proposed the three kinds of group talk. 

Whereas ‘exploring explanations’ involved advancing, extending, and adding to students’ 
ideas, ‘guiding explanations’ marked sequences headed towards the scientific explanation, including an 
effort to use scientific terms more precisely. These two categories were further divided into four granular 
typologies. Finally, ‘providing explanations’ labelled sequences in which the teacher delivered an 
explanation to the students. In this sample of talk-intensive lessons, this kind of direct telling was 
highly interactive, and students contributed with some words, but the teacher did most of the conceptual 
development. 

The full research report (Author, XXXX) discusses these forms of collective construction 
while proposing a framework of reference to each typology, providing examples from lessons, and 
commenting on them. In this paper, for a matter of space and scope, I opt to illustrate and discuss only 
one of these typologies; guiding explanations through response narrowing. 

Here, two extracts illustrate the excessive use of cued elicitation (Mercer, 1995) and Socratic 
questioning (Roth, 1996), respectively; that is, the use of limiting invitations that constrain the discourse 
to a narrow line of reasoning. Students just needed to give a few-word response to follow the explanation 
across the scientific point of view. In the first case, the lesson aim was to compare water and perfume 
evaporation. As students could not see or feel the water evaporating, the perfume played the role of 
showing that something was leaving the water and spreading into the air. The teacher developed this 
reasoning (Extract 2). 

In the teacher’s third move (line 82), she used a strong intonation (“SEE”) to reject 
a student’s answer. In the following move (line 84), she reinforced the right answer with a justification: 
“We don’t see them, these particles are tiny, they are invisible”. In the same turn, she asked about the 
reason for bringing the perfume to the classroom. Knowing that the visual effect was not the answer, a 
student argued about the feeling.  

Although this was a why-question, there was so much indication of the correct answer that 
it was not coded as a dialogic invitation. Then, in lines 87 and 88, the teacher developed a largely complete 
explanation, leaving only a final word unsaid for student completion—‘vapour’. Having this expected 
response, she moved on with the explanation relating vapour, the scent, and its spreading around the 
room. It was an explanatory construction, despite the narrow, inducing line of reasoning that the teacher 
pursued. 

In this following extract (3), students had just read the brief text about particle theory, and 
they were answering handout questions collectively. During the interactions, the teacher generally 
accepted responses including things like ‘separate’, ‘get further away from each other’, and ‘move faster’. 
She also explicitly asked for two other ‘things’ (lines 50 and 53) whereby she readily obtained ‘energy’ and 
‘freely’. The teacher seemingly aimed to find in students’ voices some keywords from the text. With these 
expected answers at hand (or their synonyms), the teacher provided the entire explanation in the last line. 
Again, these questions were not coded as dialogic (lines 50, 53, and 55) because expected answers were 
in the handout; students were merely reproducing them aloud and, as line 56 shows, hesitantly. It might 
the said that students’ text comprehension was explored, but it is harder to say that explanations were 
explored. 

Neither of the examples show clear evidence of exploring or deepening students’ ideas. 
Instead, it might be said that the teachers had clear objectives and tried to achieve them together with 
students. I would say that they were successful in highlighting the comparative analogy between water 
and perfume evaporation and emphasising a microscopic explanation of the evaporation process. The 
student contributed with few words and, apparently, followed the teachers’ line of reasoning. 

This type of micro-analysis of content of the utterances in these extracts have allowed us to 
explore some factors in more depth, like the building of conceptual understanding and results of each 
discursive strategy employed by the teacher.  It was possible to highlight a particular classroom activity 
and discursive techniques that had an impact on shaping classroom talk. 

In this paper, we have discussed two research paradigms and related them to two 
methodological approaches to analysing educational dialogue; systematic coding (positivism-quantitative) 
and sociocultural discourse analysis (interpretivism-qualitative). The first consisted of a coding scheme 
in which utterances were allocated to predefined categories that can be broadened or broken down 
further as desired. Hennessy et al. (2020) list some advantages of frequency counting, such as processing 
large quantities of data, highlighting key markers, searching the dataset efficiently to find how specific 
acts correlate with others, detecting patterns, measuring change in practice and making comparisons 
subjected to statistical analysis. 

Such method allowed us to frame a general pattern of the small-group talk that emerged in 
a Brazilian primary school, as well as to search for differences across time. This last procedure was done 
by measuring the relative frequencies of the occurrence of codes. Thus, the findings represented here 
have illustrated the positive aspects highlighted above. The great loss in this analysis is the temporal 
development of meanings and the ambiguity because utterances can have more than one functions. In 
some cases, coding is said to be atheoretical or dogmatic in their conclusions (Hennessy et al., 2020). 

The second method explored in the paper is sociocultural discourse analysis. It gives 
prominence to the contextual and situatedness of turns of speech while deepening the meaning of 
contributions. Qualitative analysis can highlight the "participants' underlying intentions and responses to 
others moreover enables the researcher to go beyond the data, for instance to identify missed 
opportunities for extension or challenge." (Hennessy et al., 2020, p. 6). Categorising extracts as a whole 
can build models rather than recording the presence/absence of target discourse moves in a way in which 
categories/typologies are generated as outcomes rather than predetermined (Mercer, 2010).  

Employing this method, it was shown how teachers and students work together to build 
scientific explanation through classroom talk. From the five typologies identified in the original work, 
only one was presented here. It was seen how teachers can guide students’ ideas through a line of 
reasoning while building explanation interactively. Strategies like confrontation, response narrowing, and 
questioning were employed. 

Although quantitative and qualitative methods have been contrasted, both methodologies 
play play relevant roles and can be seen as complementary (Snell & Lefstein, 2011). Systematic coding is 
a method for managing an extensive data set, identification of general patterns across multiple lessons 
/tasks while allowing statistical comparisons and developmental analysis (Mercer et al., 2004). On the 
other hand, sociocultural discourse analysis can explore fine-grained and offer a multi-dimensional 
understanding of the complexities of classroom dialogue (Asterhan et al., 2020). While the former 
constricts the discursive interactions into measured variables (positivist ideal), the latter reveals the 
complexity and richness of the discursive exchanges with greater interpretative vein.  

From a theoretical point of view, Filho (2013) brings an instigating theoretical discussion on 
the incommensurability, complementary, and unity of the paradigms. Researchers from the first thesis 
argue that the realism and interpretivism views are in strict opposition and therefore are incompatible.  
The ones who advocate in favour of complementarity say that both paradigms are legitimate as they are 
not in necessarily conflict. Moreover, in the empirical domain, each paradigm aligns to goals that could 
not be tackled with another. Finally, the unity between these paradigms is considered mainly by pos-
positivist and critical philosophers who defend that there is no logical and consistent way to divide 
knowledge into radical terms. 

Here, I argue for a complementarity stance mainly in the analytical-empirical dimension as 
due to the nature of the research questions, both quanti- and qualitative methods can be required for the 
educational studies (Souza & Kerbauy, 2017). That is, taking a mixed-method approach to methodology 
(Tashakkori & Teddlie, 1998), it is possible to juxtapose different languages in order to answer 
research questions properly and coherently. As a result, while exploratory research questions privilege a 
qualitative analysis, others present a confirmatory bias should employ quantitative characterizations and 
comparisons. 
